{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "# https://www.tensorflow.org/tutorials/keras/regression\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rejected 1810263 points (0.166070%)\n"
     ]
    }
   ],
   "source": [
    "column_names = ['fileId', 'row','rising_idx','falling_idx','volume','rising_weight',\n",
    "                'falling_weight', 'first_val', 'last_val', 'delay']\n",
    "def filterBad(dataset):\n",
    "    initial_len = len(dataset)\n",
    "    dataset = dataset[(dataset['rising_idx'] != 0)]\n",
    "    dataset = dataset[(dataset['falling_idx'] != 0)]\n",
    "    dataset = dataset[(dataset['volume'] > 500)]\n",
    "#     dataset = dataset[(dataset['first_val'] < 30)]\n",
    "#     dataset = dataset[(dataset['last_val'] < 30)]\n",
    "    final_len = len(dataset)\n",
    "    print('Rejected %d points (%f%%)' % ((initial_len-final_len), (initial_len-final_len)/initial_len))\n",
    "    return dataset\n",
    "\n",
    "raw_dataset =  pd.read_feather('../preprocessing/processed.feather')\n",
    "raw_dataset = filterBad(raw_dataset)\n",
    "# visualize_dataset = raw_dataset.sample(frac=0.01)\n",
    "# sns.pairplot(visualize_dataset[column_names], diag_kind=\"kde\")\n",
    "\n",
    "\n",
    "dataset = raw_dataset.copy()\n",
    "dataset.tail()\n",
    "\n",
    "dataset = dataset.dropna()\n",
    "dataset = dataset.drop(columns=['fileId', 'row'])\n",
    "dataset = pd.get_dummies(dataset, prefix='', prefix_sep='')\n",
    "# dataset.tail()\n",
    "# train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
    "# test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "# train_stats = train_dataset.describe()\n",
    "# train_stats.pop(\"delay\")\n",
    "# train_stats = train_stats.transpose()\n",
    "# train_stats\n",
    "# train_labels = train_dataset.pop('delay')\n",
    "# test_labels = test_dataset.pop('delay')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1665171    -1888.38000\n",
      "10469887     370.92400\n",
      "1593196     1147.83000\n",
      "4213913      234.00100\n",
      "4896645    -1488.40000\n",
      "10644609   -1023.21000\n",
      "10275321   -1046.29000\n",
      "5470257       -3.40788\n",
      "6999509    -1452.61000\n",
      "9164833      722.87200\n",
      "4430505     -811.18000\n",
      "4376785     2103.34000\n",
      "7717261      189.44400\n",
      "7104372      983.77300\n",
      "5449251    -1841.02000\n",
      "7269915      134.38300\n",
      "505758       208.76400\n",
      "6219525     -204.73300\n",
      "3733296      821.54200\n",
      "5839927     -200.84000\n",
      "8614007     1538.04000\n",
      "6066779      919.96000\n",
      "9543783    -1215.13000\n",
      "4277422    -1465.58000\n",
      "5514181     1145.23000\n",
      "4789881     -463.22900\n",
      "3552         491.64700\n",
      "2701117     1245.07000\n",
      "5544331      734.08200\n",
      "4261225      121.73900\n",
      "               ...    \n",
      "8015268      543.87300\n",
      "10167185     157.47600\n",
      "2408811    -1898.16000\n",
      "5725746     -141.92200\n",
      "2856693    -2485.93000\n",
      "579217     -1557.97000\n",
      "732694     -3340.65000\n",
      "8096757    -1902.52000\n",
      "9288148     2400.33000\n",
      "3728489     -242.63800\n",
      "4891079     -460.45100\n",
      "3732963       66.42990\n",
      "2823614     -830.49800\n",
      "5105134      -16.10160\n",
      "4316973      757.02200\n",
      "4774783    -1089.09000\n",
      "5356079     1017.10000\n",
      "7763888       20.04850\n",
      "10102887    -248.98900\n",
      "2947232     1176.02000\n",
      "169467      -251.26200\n",
      "2867593    -2979.15000\n",
      "3875366     -658.07800\n",
      "7359638    -1516.67000\n",
      "5521898      384.13500\n",
      "8696534     1305.17000\n",
      "2048915      616.00700\n",
      "6477297      592.55100\n",
      "1190344      652.87100\n",
      "5199454    -2617.06000\n",
      "Name: delay, Length: 1818070, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = dataset.iloc[:,:-1],dataset.iloc[:,-1]\n",
    "\n",
    "train_dataset, test_dataset, train_labels, test_labels = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "train_stats = train_dataset.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_DIM = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          rising_idx  falling_idx    volume  rising_weight  falling_weight  \\\n",
      "4389278          145          324    397895      933.50400     -1044.51000   \n",
      "5703301          333          551    309988      740.38500      -690.48500   \n",
      "2133620          230          427     28632       84.09030       -91.88660   \n",
      "7775485          157          341     35077      103.68900       -86.14610   \n",
      "9028950          139          318    136806      378.40500      -483.93800   \n",
      "7303294          195          385    200376      614.59100      -630.45500   \n",
      "1863732          598          874     16353       20.75600       -27.06440   \n",
      "3202291          181          383  10138581    24487.30000    -17317.90000   \n",
      "95605            168          353    877594     2492.53000     -2943.66000   \n",
      "10591325         379          606     38297       81.47080       -98.73130   \n",
      "6463261          258          461    155648      402.19300      -344.56000   \n",
      "516954           368          593    992140     2111.44000     -1797.50000   \n",
      "1807868          145          324    499037     1193.94000     -1321.36000   \n",
      "18974            644          932     46279       59.36590       -72.11320   \n",
      "2847569          183          315      2421        5.39215        -4.40995   \n",
      "6947910          472          718      8968       10.81410       -11.17990   \n",
      "691597           373          599   1022244     2287.99000     -2216.53000   \n",
      "10886999         219          415    321632      766.00700      -630.91600   \n",
      "7234889          345          564    446115      862.25700     -1031.27000   \n",
      "2557617           81          249    340201      970.91700     -1187.49000   \n",
      "6467145          177          370   9282068    17687.70000    -16166.80000   \n",
      "1455583           95          267     42088      132.98900      -109.36100   \n",
      "5372795          190          380     78379      222.59100      -190.27400   \n",
      "6625547          349          569     14105       22.50280       -27.27700   \n",
      "10766372          93          271   7875361    17691.40000    -19060.80000   \n",
      "7135040          588          863   2876260     4482.97000     -4421.64000   \n",
      "8536137          463          709    108833      175.81300      -216.27100   \n",
      "7159944          387          615    160246      258.76600      -303.63200   \n",
      "4025741          432          669    130094      177.02900      -172.57700   \n",
      "9599529          428          665   3458803     5246.05000     -5799.89000   \n",
      "...              ...          ...       ...            ...             ...   \n",
      "711607           258          460    441273     1121.05000      -975.71600   \n",
      "8759098          441          681   4301930     6842.33000     -5554.65000   \n",
      "8489834          112          309   9586932    24530.50000    -14903.70000   \n",
      "10378631          52          215   2381230     7360.04000     -8875.21000   \n",
      "9263446          271          476      4703       10.31350       -14.39180   \n",
      "9142085          524          782  11724983    16049.00000    -13744.70000   \n",
      "4661029          202          393   1272756     3308.03000     -3892.72000   \n",
      "8182592          200          390    477774     1327.57000     -1558.21000   \n",
      "10723518         174          378   9824823    17478.70000    -15171.40000   \n",
      "2976248          331          550      3755        9.82441        -7.79036   \n",
      "7172023          101          152     13141      171.32600      -556.53200   \n",
      "1554696           82          250    113012      311.14600      -387.43400   \n",
      "8730659          214          406    348385      736.02700      -681.33800   \n",
      "786989           270          475     94269      213.77400      -272.17600   \n",
      "5581537           93          264   2092882     6250.64000     -5543.81000   \n",
      "5520559          304          516     86894      198.40900      -244.36700   \n",
      "7685931          607          885   9225833    10319.90000    -10378.40000   \n",
      "2389276          524          781     76271       94.73580       -72.88600   \n",
      "8083171          164          349    336900     1060.31000     -1151.16000   \n",
      "6361626          326          560  11636388    15671.60000    -15074.70000   \n",
      "3956375          526          819  15680682    22435.70000    -14204.00000   \n",
      "1524528          194          385      2684        9.24264        -9.05292   \n",
      "6338542           67          235      7939       28.25240       -23.23710   \n",
      "3701912          197          388    143412      427.50500      -482.65700   \n",
      "2064843          606          884    165998      170.02800      -177.84200   \n",
      "2749591          189          396  10173447    18355.60000    -14864.90000   \n",
      "1491377          313          525    857556     1565.47000     -1730.53000   \n",
      "5060273          198          389       547        2.00902        -2.55050   \n",
      "10392748         113          286     13570       33.58460       -41.75720   \n",
      "5953562          126          304   1457405     4478.82000     -4062.97000   \n",
      "\n",
      "          first_val  last_val  \n",
      "4389278          29         0  \n",
      "5703301          13         0  \n",
      "2133620           1         0  \n",
      "7775485           2         0  \n",
      "9028950          10         0  \n",
      "7303294          12         0  \n",
      "1863732           0         0  \n",
      "3202291        1097         0  \n",
      "95605            59         0  \n",
      "10591325          1         0  \n",
      "6463261           8         0  \n",
      "516954           40         0  \n",
      "1807868          36         0  \n",
      "18974             1         0  \n",
      "2847569           0         0  \n",
      "6947910           0         0  \n",
      "691597           40         0  \n",
      "10886999         19         0  \n",
      "7234889          18         0  \n",
      "2557617          29         0  \n",
      "6467145        1479         0  \n",
      "1455583           3         0  \n",
      "5372795           5         0  \n",
      "6625547           0         0  \n",
      "10766372        736         0  \n",
      "7135040          69         0  \n",
      "8536137           3         0  \n",
      "7159944           6         0  \n",
      "4025741           4         0  \n",
      "9599529         120         0  \n",
      "...             ...       ...  \n",
      "711607           23         0  \n",
      "8759098         146         0  \n",
      "8489834        2328         0  \n",
      "10378631        180         0  \n",
      "9263446           0         0  \n",
      "9142085         331         0  \n",
      "4661029          77         0  \n",
      "8182592          29         0  \n",
      "10723518       1079         0  \n",
      "2976248           0         0  \n",
      "7172023        1272         0  \n",
      "1554696           9         0  \n",
      "8730659          21         0  \n",
      "786989            4         0  \n",
      "5581537         179         0  \n",
      "5520559           4         0  \n",
      "7685931         216         0  \n",
      "2389276           2         0  \n",
      "8083171          23         0  \n",
      "6361626         738         0  \n",
      "3956375        1375         0  \n",
      "1524528           0         0  \n",
      "6338542           0         0  \n",
      "3701912           9         0  \n",
      "2064843           4         0  \n",
      "2749591        1232         0  \n",
      "1491377          39         0  \n",
      "5060273           0         0  \n",
      "10392748          1         0  \n",
      "5953562         111         0  \n",
      "\n",
      "[7272277 rows x 7 columns]\n",
      "          rising_idx  falling_idx    volume  rising_weight  falling_weight  \\\n",
      "4389278    -0.765649    -0.757119 -0.410019      -0.426900        0.427071   \n",
      "5703301     0.402573     0.429455 -0.434277      -0.458415        0.486372   \n",
      "2133620    -0.237463    -0.218717 -0.511917      -0.565515        0.586642   \n",
      "7775485    -0.691081    -0.668256 -0.510139      -0.562317        0.587603   \n",
      "9028950    -0.802932    -0.788482 -0.482066      -0.517486        0.520970   \n",
      "7303294    -0.454951    -0.438260 -0.464524      -0.478943        0.496428   \n",
      "1863732     2.049269     2.117840 -0.515306      -0.575850        0.597500   \n",
      "3202291    -0.541947    -0.448714  2.277927       3.416819       -2.298836   \n",
      "95605      -0.622728    -0.605530 -0.277646      -0.172484        0.108950   \n",
      "10591325    0.688415     0.716951 -0.509250      -0.565942        0.585495   \n",
      "6463261    -0.063473    -0.040992 -0.476867      -0.513604        0.544317   \n",
      "516954      0.620061     0.648998 -0.246037      -0.234674        0.300940   \n",
      "1807868    -0.765649    -0.757119 -0.382109      -0.384400        0.380696   \n",
      "18974       2.335111     2.421018 -0.507047      -0.569550        0.589954   \n",
      "2847569    -0.529519    -0.804163 -0.519150      -0.578358        0.601295   \n",
      "6947910     1.266312     1.302397 -0.517343      -0.577473        0.600161   \n",
      "691597      0.651131     0.680361 -0.237730      -0.205863        0.230749   \n",
      "10886999   -0.305817    -0.281444 -0.431064      -0.454234        0.496351   \n",
      "7234889     0.477141     0.497409 -0.396713      -0.438527        0.429289   \n",
      "2557617    -1.163341    -1.149158 -0.425940      -0.420795        0.403121   \n",
      "6467145    -0.566802    -0.516667  2.041572       2.307199       -2.106019   \n",
      "1455583    -1.076346    -1.055069 -0.508204      -0.557535        0.583715   \n",
      "5372795    -0.486021    -0.464396 -0.498189      -0.542913        0.570161   \n",
      "6625547     0.501996     0.523545 -0.515926      -0.575565        0.597464   \n",
      "10766372   -1.088774    -1.034160  1.653390       2.307803       -2.590784   \n",
      "7135040     1.987130     2.060341  0.273887       0.152333       -0.138622   \n",
      "8536137     1.210386     1.255353 -0.489786      -0.550547        0.565807   \n",
      "7159944     0.738126     0.763996 -0.475598      -0.537010        0.551173   \n",
      "4025741     1.017754     1.046265 -0.483919      -0.550348        0.573126   \n",
      "9599529     0.992898     1.025356  0.434640       0.276860       -0.369489   \n",
      "...              ...          ...       ...            ...             ...   \n",
      "711607     -0.063473    -0.046220 -0.398049      -0.396295        0.438594   \n",
      "8759098     1.073680     1.108991  0.667301       0.537355       -0.328409   \n",
      "8489834    -0.970709    -0.835527  2.125699       3.423868       -1.894441   \n",
      "10378631   -1.343546    -1.326883  0.137283       0.621839       -0.884627   \n",
      "9263446     0.017309     0.037415 -0.518520      -0.577555        0.599623   \n",
      "9142085     1.589437     1.636938  2.715695       2.039781       -1.700300   \n",
      "4661029    -0.411454    -0.396442 -0.168601      -0.039404       -0.050024   \n",
      "8182592    -0.423882    -0.412124 -0.387976      -0.362593        0.341022   \n",
      "10723518   -0.585444    -0.474850  2.191345       2.273093       -1.939283   \n",
      "2976248     0.390145     0.424228 -0.518782      -0.577634        0.600729   \n",
      "7172023    -1.039062    -1.656197 -0.516192      -0.551279        0.508810   \n",
      "1554696    -1.157127    -1.143931 -0.488632      -0.528462        0.537136   \n",
      "8730659    -0.336886    -0.328488 -0.423681      -0.459126        0.487905   \n",
      "786989      0.011095     0.032188 -0.493805      -0.544352        0.556442   \n",
      "5581537    -1.088774    -1.070750  0.057713       0.440798       -0.326594   \n",
      "5520559     0.222369     0.246503 -0.495840      -0.546859        0.561100   \n",
      "7685931     2.105195     2.175339  2.026054       1.104856       -1.136421   \n",
      "2389276     1.589437     1.631711 -0.498771      -0.563778        0.589825   \n",
      "8083171    -0.647584    -0.626439 -0.426850      -0.406207        0.409206   \n",
      "6361626     0.359076     0.476500  2.691247       1.978194       -1.923085   \n",
      "3956375     1.601865     1.830344  3.807272       3.082020       -1.777236   \n",
      "1524528    -0.461165    -0.438260 -0.519077      -0.577729        0.600517   \n",
      "6338542    -1.250337    -1.222339 -0.517627      -0.574627        0.598141   \n",
      "3701912    -0.442523    -0.422578 -0.480244      -0.509474        0.521185   \n",
      "2064843     2.098981     2.170112 -0.474011      -0.551491        0.572244   \n",
      "2749591    -0.492235    -0.380760  2.287548       2.416193       -1.887942   \n",
      "1491377     0.278294     0.293548 -0.283175      -0.323770        0.312158   \n",
      "5060273    -0.436310    -0.417351 -0.519667      -0.578910        0.601606   \n",
      "10392748   -0.964495    -0.955752 -0.516073      -0.573757        0.595039   \n",
      "5953562    -0.883714    -0.861663 -0.117647       0.151656       -0.078543   \n",
      "\n",
      "          first_val  last_val  \n",
      "4389278   -0.172840 -0.045343  \n",
      "5703301   -0.176031 -0.045343  \n",
      "2133620   -0.178423 -0.045343  \n",
      "7775485   -0.178224 -0.045343  \n",
      "9028950   -0.176629 -0.045343  \n",
      "7303294   -0.176230 -0.045343  \n",
      "1863732   -0.178623 -0.045343  \n",
      "3202291    0.040113 -0.045343  \n",
      "95605     -0.166858 -0.045343  \n",
      "10591325  -0.178423 -0.045343  \n",
      "6463261   -0.177028 -0.045343  \n",
      "516954    -0.170647 -0.045343  \n",
      "1807868   -0.171444 -0.045343  \n",
      "18974     -0.178423 -0.045343  \n",
      "2847569   -0.178623 -0.045343  \n",
      "6947910   -0.178623 -0.045343  \n",
      "691597    -0.170647 -0.045343  \n",
      "10886999  -0.174834 -0.045343  \n",
      "7234889   -0.175034 -0.045343  \n",
      "2557617   -0.172840 -0.045343  \n",
      "6467145    0.116281 -0.045343  \n",
      "1455583   -0.178025 -0.045343  \n",
      "5372795   -0.177626 -0.045343  \n",
      "6625547   -0.178623 -0.045343  \n",
      "10766372  -0.031869 -0.045343  \n",
      "7135040   -0.164864 -0.045343  \n",
      "8536137   -0.178025 -0.045343  \n",
      "7159944   -0.177426 -0.045343  \n",
      "4025741   -0.177825 -0.045343  \n",
      "9599529   -0.154695 -0.045343  \n",
      "...             ...       ...  \n",
      "711607    -0.174037 -0.045343  \n",
      "8759098   -0.149511 -0.045343  \n",
      "8489834    0.285567 -0.045343  \n",
      "10378631  -0.142732 -0.045343  \n",
      "9263446   -0.178623 -0.045343  \n",
      "9142085   -0.112623 -0.045343  \n",
      "4661029   -0.163269 -0.045343  \n",
      "8182592   -0.172840 -0.045343  \n",
      "10723518   0.036524 -0.045343  \n",
      "2976248   -0.178623 -0.045343  \n",
      "7172023    0.075007 -0.045343  \n",
      "1554696   -0.176828 -0.045343  \n",
      "8730659   -0.174435 -0.045343  \n",
      "786989    -0.177825 -0.045343  \n",
      "5581537   -0.142931 -0.045343  \n",
      "5520559   -0.177825 -0.045343  \n",
      "7685931   -0.135554 -0.045343  \n",
      "2389276   -0.178224 -0.045343  \n",
      "8083171   -0.174037 -0.045343  \n",
      "6361626   -0.031470 -0.045343  \n",
      "3956375    0.095544 -0.045343  \n",
      "1524528   -0.178623 -0.045343  \n",
      "6338542   -0.178623 -0.045343  \n",
      "3701912   -0.176828 -0.045343  \n",
      "2064843   -0.177825 -0.045343  \n",
      "2749591    0.067031 -0.045343  \n",
      "1491377   -0.170846 -0.045343  \n",
      "5060273   -0.178623 -0.045343  \n",
      "10392748  -0.178423 -0.045343  \n",
      "5953562   -0.156490 -0.045343  \n",
      "\n",
      "[7272277 rows x 7 columns]\n",
      "rising_idx        2.682146e+02\n",
      "falling_idx       4.688422e+02\n",
      "volume            1.883738e+06\n",
      "rising_weight     3.549491e+03\n",
      "falling_weight   -3.594079e+03\n",
      "first_val         8.958267e+02\n",
      "last_val          8.825798e+01\n",
      "Name: mean, dtype: float64\n",
      "WARNING:tensorflow:From /home/mattfel/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "def norm(x):\n",
    "  return (x - train_stats['mean']) / train_stats['std']\n",
    "\n",
    "normed_train_data = norm(train_dataset)\n",
    "normed_test_data = norm(test_dataset)\n",
    "\n",
    "\n",
    "print(train_dataset)\n",
    "print(normed_train_data)\n",
    "print(train_stats['mean'])\n",
    "def build_model():\n",
    "  model = keras.Sequential([\n",
    "    layers.Dense(L1_DIM, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
    "#     layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "  model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "  return model\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                512       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 577\n",
      "Trainable params: 577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, loss:5269.2334,  mean_absolute_error:23.8322,  mean_squared_error:5269.2305,  val_loss:3879.7772,  val_mean_absolute_error:16.8007,  val_mean_squared_error:3879.7534,  \n",
      "........"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f5af25ba5684>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mnormed_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   callbacks=[tfdocs.modeling.EpochDots()])\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#     callbacks = callbacks_list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()\n",
    "\n",
    "# example_batch = normed_train_data[:10]\n",
    "# example_result = model.predict(example_batch)\n",
    "# example_result\n",
    "\n",
    "EPOCHS = 15\n",
    "\n",
    "# filepath=\"ckpoints.hdf5\"\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "# callbacks_list = [checkpoint]\n",
    "\n",
    "history = model.fit(\n",
    "  normed_train_data, train_labels,\n",
    "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
    "  callbacks=[tfdocs.modeling.EpochDots()])\n",
    "#     callbacks = callbacks_list)\n",
    "\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE, MAE, r2: 1848.124631 11.616834 0.998699\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# tf.keras.utils.plot_model(model, to_file='model.png')\n",
    "\n",
    "# plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)\n",
    "\n",
    "\n",
    "# loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=2)\n",
    "preds = model.predict(normed_test_data)\n",
    "rmse = mean_squared_error(test_labels, preds)\n",
    "rmae = mean_absolute_error(test_labels, preds)\n",
    "r2 = r2_score(test_labels, preds)\n",
    "print(\"MSE, MAE, r2: %f %f %f\" % (rmse, rmae, r2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val mean = FULLFEATURES(268.2145561837097,468.8421516397134,1883737.9202614257,3549.49099375219,-3594.0790894527363,895.8266651559064,88.2579832973909)\n",
      "val l1W = Seq(0.017414.to[T],0.043573.to[T],0.001617.to[T],0.063180.to[T],0.010253.to[T],-0.023324.to[T],0.008253.to[T],-0.099895.to[T],0.042064.to[T],0.019148.to[T],0.054045.to[T],-0.076539.to[T],0.009661.to[T],-0.030295.to[T],0.011007.to[T],0.014330.to[T],-0.033842.to[T],-0.022774.to[T],-0.054721.to[T],0.038924.to[T],-0.035612.to[T],-0.000166.to[T],0.075991.to[T],0.028132.to[T],0.020888.to[T],0.036434.to[T],-0.117659.to[T],0.042636.to[T],-0.056284.to[T],-0.075248.to[T],-0.057049.to[T],-0.101635.to[T],-0.038393.to[T],0.010143.to[T],0.044220.to[T],0.012465.to[T],0.005401.to[T],0.009410.to[T],0.003110.to[T],0.061756.to[T],0.014013.to[T],0.010328.to[T],0.048747.to[T],0.029928.to[T],-0.030564.to[T],0.068709.to[T],-0.108280.to[T],-0.077954.to[T],-0.047952.to[T],0.051305.to[T],0.003847.to[T],-0.035289.to[T],0.000023.to[T],0.024519.to[T],0.047608.to[T],0.001873.to[T],-0.041549.to[T],0.027198.to[T],-0.073840.to[T],0.001554.to[T],0.008355.to[T],0.019199.to[T],0.023777.to[T],0.032031.to[T],0.018900.to[T],-0.004675.to[T],-0.000546.to[T],0.020587.to[T],0.005175.to[T],-0.014653.to[T],0.001434.to[T],-0.072832.to[T],-0.091915.to[T],0.006110.to[T],-0.021300.to[T],-0.003393.to[T],-0.036636.to[T],-0.009419.to[T],0.004982.to[T],0.005334.to[T],-0.066752.to[T],0.013777.to[T],-0.013123.to[T],-0.020114.to[T],-0.024127.to[T],0.011576.to[T],0.004923.to[T],0.010891.to[T],-0.063219.to[T],-0.014721.to[T],-0.061744.to[T],-0.066193.to[T],0.010872.to[T],0.007646.to[T],-0.019087.to[T],-0.065803.to[T],-0.009433.to[T],-0.073913.to[T],-0.012878.to[T],-0.025740.to[T],-0.004208.to[T],0.002050.to[T],0.015528.to[T],-0.016534.to[T],0.019261.to[T],0.005931.to[T],-0.019633.to[T],-0.009225.to[T],-0.001014.to[T],0.032809.to[T],-0.043660.to[T],0.001122.to[T],-0.057106.to[T],-0.104670.to[T],0.001203.to[T],-0.047354.to[T],-0.022441.to[T],-0.035343.to[T],0.020997.to[T],0.004001.to[T],0.010787.to[T],-0.055530.to[T],-0.011586.to[T],0.001319.to[T],0.002683.to[T],0.006455.to[T],-0.006165.to[T],-0.012849.to[T],-0.000001.to[T],0.000002.to[T],-0.000000.to[T],0.000002.to[T],-0.000000.to[T],0.000001.to[T],-0.000000.to[T],0.000002.to[T],0.000010.to[T],-0.000002.to[T],0.000001.to[T],0.000003.to[T],0.000000.to[T],-0.000006.to[T],-0.000001.to[T],0.000004.to[T],0.000002.to[T],0.000000.to[T],0.000001.to[T],0.000004.to[T],0.000001.to[T],-0.000000.to[T],0.000004.to[T],-0.000002.to[T],0.000000.to[T],0.000004.to[T],0.000002.to[T],-0.000003.to[T],-0.000001.to[T],0.000002.to[T],0.000001.to[T],0.000002.to[T],0.000002.to[T],0.000007.to[T],0.000003.to[T],-0.000000.to[T],0.000004.to[T],-0.000001.to[T],-0.000001.to[T],0.000004.to[T],-0.000002.to[T],-0.000000.to[T],0.000004.to[T],-0.000001.to[T],-0.000005.to[T],0.000006.to[T],0.000001.to[T],0.000002.to[T],0.000000.to[T],0.000002.to[T],-0.000001.to[T],0.000006.to[T],-0.000000.to[T],0.000008.to[T],-0.000000.to[T],-0.000000.to[T],-0.000003.to[T],0.000000.to[T],0.000002.to[T],-0.000001.to[T],-0.000001.to[T],0.000000.to[T],0.000004.to[T],0.000005.to[T],0.000012.to[T],-0.000319.to[T],-0.000807.to[T],-0.000481.to[T],-0.000126.to[T],-0.000374.to[T],-0.000383.to[T],0.000737.to[T],-0.000528.to[T],-0.000494.to[T],0.001195.to[T],-0.000108.to[T],0.000104.to[T],0.000359.to[T],-0.000052.to[T],-0.001290.to[T],-0.000455.to[T],-0.000146.to[T],0.000010.to[T],-0.000806.to[T],-0.000037.to[T],-0.000233.to[T],-0.000385.to[T],0.000381.to[T],-0.000175.to[T],-0.000753.to[T],0.000497.to[T],-0.000356.to[T],0.000065.to[T],0.000168.to[T],-0.000190.to[T],0.000673.to[T],-0.000612.to[T],-0.000346.to[T],-0.000426.to[T],0.000274.to[T],-0.001069.to[T],-0.000324.to[T],0.000183.to[T],-0.000668.to[T],0.000153.to[T],-0.000031.to[T],-0.000659.to[T],-0.000789.to[T],0.000792.to[T],-0.000699.to[T],0.000392.to[T],-0.000059.to[T],0.000387.to[T],-0.000100.to[T],-0.000423.to[T],0.000034.to[T],0.000179.to[T],-0.000771.to[T],-0.000035.to[T],-0.000293.to[T],0.000653.to[T],0.000578.to[T],0.000031.to[T],-0.000743.to[T],-0.000568.to[T],0.000022.to[T],-0.001123.to[T],-0.000888.to[T],0.000106.to[T],0.000256.to[T],-0.000636.to[T],-0.000201.to[T],-0.000182.to[T],0.000463.to[T],-0.000282.to[T],-0.000224.to[T],-0.000631.to[T],0.000019.to[T],0.000221.to[T],0.000153.to[T],-0.000104.to[T],0.000230.to[T],0.000100.to[T],-0.000257.to[T],0.000009.to[T],-0.000201.to[T],-0.000119.to[T],0.000118.to[T],0.000149.to[T],-0.000268.to[T],0.000831.to[T],0.000013.to[T],-0.000191.to[T],0.000280.to[T],0.000155.to[T],-0.000279.to[T],-0.000090.to[T],-0.000178.to[T],0.000582.to[T],-0.000431.to[T],0.000603.to[T],-0.000058.to[T],0.000359.to[T],0.000042.to[T],-0.000022.to[T],-0.000323.to[T],0.000056.to[T],0.000303.to[T],-0.000315.to[T],-0.000139.to[T],0.000448.to[T],-0.000185.to[T],-0.000463.to[T],0.000394.to[T],0.000021.to[T],0.000251.to[T],-0.000320.to[T],0.000135.to[T],-0.000388.to[T],0.000077.to[T],-0.000116.to[T],-0.000475.to[T],-0.000152.to[T],-0.000250.to[T],-0.000281.to[T],0.000279.to[T],0.000129.to[T],-0.000667.to[T],-0.000368.to[T],0.000035.to[T],-0.000185.to[T],0.000124.to[T],-0.001703.to[T],-0.000720.to[T],-0.004276.to[T],-0.000326.to[T],-0.005180.to[T],0.000138.to[T],-0.004394.to[T],0.000645.to[T],-0.001827.to[T],-0.002609.to[T],-0.000087.to[T],0.000215.to[T],0.000467.to[T],-0.000130.to[T],-0.001173.to[T],-0.000080.to[T],0.000429.to[T],-0.003368.to[T],0.000162.to[T],-0.000040.to[T],0.000006.to[T],-0.005012.to[T],0.000388.to[T],-0.001551.to[T],-0.000014.to[T],-0.000438.to[T],0.000868.to[T],-0.000028.to[T],0.000350.to[T],0.000128.to[T],0.000444.to[T],0.000580.to[T],0.000056.to[T],-0.000174.to[T],-0.000454.to[T],0.000112.to[T],-0.000106.to[T],-0.004894.to[T],-0.000309.to[T],0.000029.to[T],-0.001653.to[T],-0.004816.to[T],-0.000308.to[T],-0.000973.to[T],-0.000948.to[T],0.000077.to[T],0.000696.to[T],0.000400.to[T],0.000111.to[T],-0.000058.to[T],-0.004140.to[T],-0.000044.to[T],0.000444.to[T],-0.000220.to[T],0.000113.to[T],-0.004278.to[T],-0.000048.to[T],0.000134.to[T],0.000285.to[T],-0.003179.to[T],-0.002886.to[T],-0.002638.to[T],-0.000069.to[T],-0.000145.to[T],-0.000362.to[T],0.000119.to[T],0.000108.to[T],-0.000309.to[T],-0.000117.to[T],-0.007363.to[T],-0.000006.to[T],-0.002052.to[T],0.001897.to[T],0.000287.to[T],0.000043.to[T],-0.006612.to[T],-0.000403.to[T],0.000045.to[T],0.000534.to[T],-0.000841.to[T],0.000663.to[T],-0.004833.to[T],0.000567.to[T],0.000404.to[T],0.000418.to[T],-0.000085.to[T],-0.000480.to[T],0.000596.to[T],-0.000138.to[T],-0.000365.to[T],-0.002839.to[T],0.000385.to[T],0.000297.to[T],0.000538.to[T],-0.009082.to[T],-0.002057.to[T],0.000495.to[T],0.000510.to[T],-0.000507.to[T],-0.000076.to[T],-0.000277.to[T],-0.000044.to[T],0.000262.to[T],-0.000232.to[T],0.000166.to[T],-0.000148.to[T],-0.000014.to[T],0.001863.to[T],-0.000569.to[T],-0.000860.to[T],-0.005015.to[T],0.000768.to[T],-0.000636.to[T],-0.000053.to[T],-0.000043.to[T],0.000396.to[T],0.000296.to[T],0.001840.to[T],-0.001484.to[T],0.000001.to[T],-0.001706.to[T],0.000521.to[T],-0.003289.to[T],0.000093.to[T],0.000024.to[T],-0.000562.to[T],-0.000246.to[T],-0.000307.to[T])\n",
      "val l1B = Seq(4.523528.to[T],2.152960.to[T],-4.437245.to[T],1.528525.to[T],-1.923081.to[T],14.305655.to[T],-3.236490.to[T],2.158864.to[T],4.893695.to[T],-2.722683.to[T],4.774311.to[T],13.851906.to[T],0.491256.to[T],-9.643332.to[T],14.268316.to[T],7.500742.to[T],-8.417539.to[T],-0.790243.to[T],-1.340368.to[T],2.115675.to[T],-2.329576.to[T],-0.724815.to[T],3.604839.to[T],3.955200.to[T],-7.948892.to[T],4.399751.to[T],5.672191.to[T],-13.353348.to[T],-2.681845.to[T],5.874283.to[T],17.547440.to[T],2.440075.to[T],-1.604452.to[T],0.280343.to[T],4.610263.to[T],-0.790018.to[T],3.702071.to[T],-4.055440.to[T],3.688032.to[T],4.630340.to[T],8.405644.to[T],-1.337802.to[T],4.355371.to[T],-3.864473.to[T],-3.576183.to[T],2.957311.to[T],8.986975.to[T],3.343666.to[T],-4.484902.to[T],-9.946840.to[T],-3.719611.to[T],2.855958.to[T],-1.505406.to[T],9.325328.to[T],2.205889.to[T],-2.148154.to[T],1.436734.to[T],11.219864.to[T],5.970500.to[T],-3.526473.to[T],-3.338390.to[T],2.466240.to[T],5.536095.to[T],4.980515.to[T])\n",
      "val l2W = Seq(-0.044755.to[T],-0.045427.to[T],-0.201265.to[T],0.039563.to[T],-0.091855.to[T],0.115186.to[T],-0.087543.to[T],0.000841.to[T],0.028652.to[T],-0.064843.to[T],-0.103338.to[T],0.024717.to[T],-0.064150.to[T],0.121236.to[T],-0.076674.to[T],-0.068044.to[T],0.034895.to[T],-0.057469.to[T],-0.007461.to[T],-0.038741.to[T],-0.019780.to[T],-0.068943.to[T],-0.041900.to[T],-0.066774.to[T],0.131528.to[T],-0.017252.to[T],0.004565.to[T],0.373248.to[T],0.048973.to[T],0.005802.to[T],0.097616.to[T],0.002720.to[T],-0.011998.to[T],0.035785.to[T],-0.031679.to[T],-0.041484.to[T],-0.038632.to[T],-0.082252.to[T],-0.047592.to[T],-0.020753.to[T],-0.067194.to[T],-0.085413.to[T],-0.003471.to[T],-0.045498.to[T],0.083588.to[T],-0.014536.to[T],0.015770.to[T],0.009706.to[T],0.057538.to[T],0.097154.to[T],-0.084093.to[T],0.001666.to[T],-0.056955.to[T],0.023362.to[T],0.024226.to[T],-0.074308.to[T],0.043550.to[T],-0.097692.to[T],0.000118.to[T],-0.087197.to[T],-0.065991.to[T],-0.033410.to[T],-0.057578.to[T],-0.016593.to[T])\n",
      "val l2B = Seq(-6.023427.to[T])\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "print('val mean = FULLFEATURES(%s)' % ','.join([str(train_stats['mean'][x]) for x in column_names[2:-1]]))\n",
    "#activation(dot(input, kernel) + bias)\n",
    "for layer in model.get_weights():\n",
    "    s = 'W' if (i % 2 == 0) else 'B'\n",
    "    vals = []\n",
    "    for j,x in enumerate(layer.flatten()):\n",
    "        if (i % 2 == 0):\n",
    "            ft = column_names[2:-1][int(j / L1_DIM)]\n",
    "            scaled = x / train_stats['std'][ft]\n",
    "            vals.append('%f.to[T]' % scaled)\n",
    "        else:\n",
    "            vals.append('%f.to[T]' % x)\n",
    "    print('val l%d%s = Seq(%s)' % (1+i//2, s, ','.join(vals)))\n",
    "#     print('Layer %d' % i)\n",
    "#     print(layer)\n",
    "    i =  i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[497.21515]]\n",
      "True label = 509.093000\n"
     ]
    }
   ],
   "source": [
    "# df2 = xgb.DMatrix(pd.DataFrame({\"rising_idx\":[157],\n",
    "#     \"falling_idx\":[341],\n",
    "#     \"volume\":[12039],\n",
    "#     \"rising_weight\":[35.2498],\n",
    "#     \"falling_weight\":[-28.1037]}))\n",
    "df2 = pd.DataFrame({\"rising_idx\":[157],\n",
    "    \"falling_idx\":[341],\n",
    "    \"volume\":[12039],\n",
    "    \"rising_weight\":[35.2498],\n",
    "    \"falling_weight\":[-28.1037], \n",
    "    \"first_val\":[12],\n",
    "    \"last_val\":[0]})\n",
    "print(model.predict(norm(df2)))\n",
    "print('True label = %f' % 509.093)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "      <th>val_mean_squared_error</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1960.505538</td>\n",
       "      <td>11.085601</td>\n",
       "      <td>1960.495850</td>\n",
       "      <td>1977.193724</td>\n",
       "      <td>10.932296</td>\n",
       "      <td>1977.186646</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1909.706727</td>\n",
       "      <td>10.885015</td>\n",
       "      <td>1909.700684</td>\n",
       "      <td>1915.721155</td>\n",
       "      <td>10.794977</td>\n",
       "      <td>1915.719360</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1828.697132</td>\n",
       "      <td>10.612532</td>\n",
       "      <td>1828.684204</td>\n",
       "      <td>1853.169155</td>\n",
       "      <td>10.450208</td>\n",
       "      <td>1853.172729</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744.994297</td>\n",
       "      <td>10.301882</td>\n",
       "      <td>1744.984497</td>\n",
       "      <td>1744.437534</td>\n",
       "      <td>10.109297</td>\n",
       "      <td>1744.441040</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1672.969164</td>\n",
       "      <td>10.100968</td>\n",
       "      <td>1672.969727</td>\n",
       "      <td>1719.620754</td>\n",
       "      <td>10.042290</td>\n",
       "      <td>1719.632080</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1642.198482</td>\n",
       "      <td>10.008043</td>\n",
       "      <td>1642.208374</td>\n",
       "      <td>1687.393910</td>\n",
       "      <td>9.925940</td>\n",
       "      <td>1687.396729</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1618.648786</td>\n",
       "      <td>9.920607</td>\n",
       "      <td>1618.653564</td>\n",
       "      <td>1645.547099</td>\n",
       "      <td>9.809487</td>\n",
       "      <td>1645.541016</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1600.134799</td>\n",
       "      <td>9.862710</td>\n",
       "      <td>1600.137573</td>\n",
       "      <td>1656.181159</td>\n",
       "      <td>9.924092</td>\n",
       "      <td>1656.178833</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1580.953250</td>\n",
       "      <td>9.798059</td>\n",
       "      <td>1580.948364</td>\n",
       "      <td>1629.672884</td>\n",
       "      <td>9.983445</td>\n",
       "      <td>1629.671753</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1564.923712</td>\n",
       "      <td>9.765280</td>\n",
       "      <td>1564.912354</td>\n",
       "      <td>1617.099227</td>\n",
       "      <td>9.930725</td>\n",
       "      <td>1617.101196</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1557.295057</td>\n",
       "      <td>9.756149</td>\n",
       "      <td>1557.296387</td>\n",
       "      <td>1604.847490</td>\n",
       "      <td>9.814301</td>\n",
       "      <td>1604.841187</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1533.137253</td>\n",
       "      <td>9.740894</td>\n",
       "      <td>1533.137085</td>\n",
       "      <td>1593.489502</td>\n",
       "      <td>9.635554</td>\n",
       "      <td>1593.489380</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1513.096974</td>\n",
       "      <td>9.730241</td>\n",
       "      <td>1513.074341</td>\n",
       "      <td>1566.101312</td>\n",
       "      <td>9.757917</td>\n",
       "      <td>1566.110840</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1496.476220</td>\n",
       "      <td>9.716362</td>\n",
       "      <td>1496.480225</td>\n",
       "      <td>1542.421586</td>\n",
       "      <td>9.647374</td>\n",
       "      <td>1542.425415</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1472.560089</td>\n",
       "      <td>9.662549</td>\n",
       "      <td>1472.560791</td>\n",
       "      <td>1515.027286</td>\n",
       "      <td>9.536309</td>\n",
       "      <td>1515.022461</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1445.129719</td>\n",
       "      <td>9.619605</td>\n",
       "      <td>1445.110474</td>\n",
       "      <td>1499.138709</td>\n",
       "      <td>9.542570</td>\n",
       "      <td>1499.144043</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1433.998351</td>\n",
       "      <td>9.569892</td>\n",
       "      <td>1433.998901</td>\n",
       "      <td>1501.031964</td>\n",
       "      <td>9.638397</td>\n",
       "      <td>1501.036011</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1418.675881</td>\n",
       "      <td>9.473996</td>\n",
       "      <td>1418.678223</td>\n",
       "      <td>1467.606539</td>\n",
       "      <td>9.334167</td>\n",
       "      <td>1467.598633</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1389.776983</td>\n",
       "      <td>9.431496</td>\n",
       "      <td>1389.778809</td>\n",
       "      <td>1478.381055</td>\n",
       "      <td>9.551398</td>\n",
       "      <td>1478.378052</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1369.985799</td>\n",
       "      <td>9.414393</td>\n",
       "      <td>1369.967285</td>\n",
       "      <td>1443.714888</td>\n",
       "      <td>9.527734</td>\n",
       "      <td>1443.714966</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1371.319403</td>\n",
       "      <td>9.401914</td>\n",
       "      <td>1371.323364</td>\n",
       "      <td>1432.826771</td>\n",
       "      <td>9.755646</td>\n",
       "      <td>1432.823730</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1344.497849</td>\n",
       "      <td>9.353391</td>\n",
       "      <td>1344.492676</td>\n",
       "      <td>1424.751464</td>\n",
       "      <td>9.368645</td>\n",
       "      <td>1424.756226</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1335.926158</td>\n",
       "      <td>9.328382</td>\n",
       "      <td>1335.918945</td>\n",
       "      <td>1405.113278</td>\n",
       "      <td>9.241011</td>\n",
       "      <td>1405.113037</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1324.774696</td>\n",
       "      <td>9.292337</td>\n",
       "      <td>1324.778076</td>\n",
       "      <td>1405.907752</td>\n",
       "      <td>9.261625</td>\n",
       "      <td>1405.908936</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1322.010429</td>\n",
       "      <td>9.273429</td>\n",
       "      <td>1322.016479</td>\n",
       "      <td>1376.995722</td>\n",
       "      <td>9.216565</td>\n",
       "      <td>1376.997070</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1305.528167</td>\n",
       "      <td>9.270911</td>\n",
       "      <td>1305.527832</td>\n",
       "      <td>1376.530576</td>\n",
       "      <td>9.561979</td>\n",
       "      <td>1376.529297</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1294.170035</td>\n",
       "      <td>9.269855</td>\n",
       "      <td>1294.171509</td>\n",
       "      <td>1365.404569</td>\n",
       "      <td>9.298976</td>\n",
       "      <td>1365.399170</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1277.990579</td>\n",
       "      <td>9.253692</td>\n",
       "      <td>1277.981323</td>\n",
       "      <td>1367.721230</td>\n",
       "      <td>9.498814</td>\n",
       "      <td>1367.723999</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1252.727570</td>\n",
       "      <td>9.226893</td>\n",
       "      <td>1252.740234</td>\n",
       "      <td>1292.737911</td>\n",
       "      <td>9.258724</td>\n",
       "      <td>1292.742798</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1207.353340</td>\n",
       "      <td>9.153671</td>\n",
       "      <td>1207.338135</td>\n",
       "      <td>1254.450771</td>\n",
       "      <td>9.032564</td>\n",
       "      <td>1254.444946</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1018.276246</td>\n",
       "      <td>8.733221</td>\n",
       "      <td>1018.272400</td>\n",
       "      <td>1068.270557</td>\n",
       "      <td>8.540742</td>\n",
       "      <td>1068.274048</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1009.440059</td>\n",
       "      <td>8.700762</td>\n",
       "      <td>1009.438110</td>\n",
       "      <td>1089.764413</td>\n",
       "      <td>9.191953</td>\n",
       "      <td>1089.763306</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1004.789436</td>\n",
       "      <td>8.681417</td>\n",
       "      <td>1004.779175</td>\n",
       "      <td>1088.496087</td>\n",
       "      <td>8.803307</td>\n",
       "      <td>1088.495361</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1003.010928</td>\n",
       "      <td>8.660819</td>\n",
       "      <td>1003.025391</td>\n",
       "      <td>1058.356513</td>\n",
       "      <td>8.506585</td>\n",
       "      <td>1058.355591</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>998.833574</td>\n",
       "      <td>8.656103</td>\n",
       "      <td>998.831604</td>\n",
       "      <td>1074.967316</td>\n",
       "      <td>8.868889</td>\n",
       "      <td>1074.965210</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1000.553477</td>\n",
       "      <td>8.650024</td>\n",
       "      <td>1000.566162</td>\n",
       "      <td>1073.363059</td>\n",
       "      <td>8.878466</td>\n",
       "      <td>1073.371216</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1000.159576</td>\n",
       "      <td>8.644251</td>\n",
       "      <td>1000.147888</td>\n",
       "      <td>1054.486882</td>\n",
       "      <td>8.450307</td>\n",
       "      <td>1054.481323</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>998.472123</td>\n",
       "      <td>8.645750</td>\n",
       "      <td>998.471436</td>\n",
       "      <td>1071.629961</td>\n",
       "      <td>8.781075</td>\n",
       "      <td>1071.635498</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>996.705941</td>\n",
       "      <td>8.639237</td>\n",
       "      <td>996.711182</td>\n",
       "      <td>1063.637090</td>\n",
       "      <td>8.563958</td>\n",
       "      <td>1063.634033</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>996.244009</td>\n",
       "      <td>8.636581</td>\n",
       "      <td>996.243591</td>\n",
       "      <td>1053.085399</td>\n",
       "      <td>8.538595</td>\n",
       "      <td>1053.080444</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>988.786217</td>\n",
       "      <td>8.635191</td>\n",
       "      <td>988.784241</td>\n",
       "      <td>1064.350065</td>\n",
       "      <td>8.491701</td>\n",
       "      <td>1064.347168</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>982.573304</td>\n",
       "      <td>8.614997</td>\n",
       "      <td>982.568237</td>\n",
       "      <td>1039.542201</td>\n",
       "      <td>8.508296</td>\n",
       "      <td>1039.540405</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>976.315092</td>\n",
       "      <td>8.610019</td>\n",
       "      <td>976.320251</td>\n",
       "      <td>1045.099806</td>\n",
       "      <td>8.860886</td>\n",
       "      <td>1045.094849</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>973.156490</td>\n",
       "      <td>8.607632</td>\n",
       "      <td>973.162476</td>\n",
       "      <td>1023.765564</td>\n",
       "      <td>8.355792</td>\n",
       "      <td>1023.769104</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>967.550879</td>\n",
       "      <td>8.597527</td>\n",
       "      <td>967.540833</td>\n",
       "      <td>1048.205990</td>\n",
       "      <td>8.509310</td>\n",
       "      <td>1048.202026</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>962.959775</td>\n",
       "      <td>8.586664</td>\n",
       "      <td>962.970947</td>\n",
       "      <td>1031.245019</td>\n",
       "      <td>8.476836</td>\n",
       "      <td>1031.248169</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>968.239036</td>\n",
       "      <td>8.590590</td>\n",
       "      <td>968.245728</td>\n",
       "      <td>1046.636130</td>\n",
       "      <td>8.602034</td>\n",
       "      <td>1046.637939</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>970.707476</td>\n",
       "      <td>8.598314</td>\n",
       "      <td>970.718079</td>\n",
       "      <td>1062.044761</td>\n",
       "      <td>8.865154</td>\n",
       "      <td>1062.044922</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>972.070557</td>\n",
       "      <td>8.597642</td>\n",
       "      <td>972.057495</td>\n",
       "      <td>1037.197236</td>\n",
       "      <td>8.469958</td>\n",
       "      <td>1037.197388</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>960.071002</td>\n",
       "      <td>8.592305</td>\n",
       "      <td>960.070435</td>\n",
       "      <td>1021.088386</td>\n",
       "      <td>8.370193</td>\n",
       "      <td>1021.082642</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>958.631588</td>\n",
       "      <td>8.597425</td>\n",
       "      <td>958.624268</td>\n",
       "      <td>1036.237883</td>\n",
       "      <td>8.892288</td>\n",
       "      <td>1036.236816</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>958.984170</td>\n",
       "      <td>8.603883</td>\n",
       "      <td>958.982971</td>\n",
       "      <td>1024.950887</td>\n",
       "      <td>8.671714</td>\n",
       "      <td>1024.954590</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>957.046754</td>\n",
       "      <td>8.611216</td>\n",
       "      <td>957.044556</td>\n",
       "      <td>1022.887621</td>\n",
       "      <td>8.443459</td>\n",
       "      <td>1022.887634</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>949.134043</td>\n",
       "      <td>8.608199</td>\n",
       "      <td>949.132812</td>\n",
       "      <td>1015.087136</td>\n",
       "      <td>8.575620</td>\n",
       "      <td>1015.081116</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>953.743137</td>\n",
       "      <td>8.610863</td>\n",
       "      <td>953.746399</td>\n",
       "      <td>1022.570636</td>\n",
       "      <td>8.395283</td>\n",
       "      <td>1022.568054</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>955.615272</td>\n",
       "      <td>8.617002</td>\n",
       "      <td>955.608643</td>\n",
       "      <td>1022.172815</td>\n",
       "      <td>8.511609</td>\n",
       "      <td>1022.174072</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>953.865778</td>\n",
       "      <td>8.617057</td>\n",
       "      <td>953.876099</td>\n",
       "      <td>1004.477572</td>\n",
       "      <td>8.596503</td>\n",
       "      <td>1004.481079</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>951.716290</td>\n",
       "      <td>8.619240</td>\n",
       "      <td>951.716797</td>\n",
       "      <td>1023.319044</td>\n",
       "      <td>8.519594</td>\n",
       "      <td>1023.314087</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>957.484109</td>\n",
       "      <td>8.630308</td>\n",
       "      <td>957.485413</td>\n",
       "      <td>1015.595881</td>\n",
       "      <td>8.405902</td>\n",
       "      <td>1015.600586</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>954.182760</td>\n",
       "      <td>8.634252</td>\n",
       "      <td>954.193115</td>\n",
       "      <td>1040.874896</td>\n",
       "      <td>8.950229</td>\n",
       "      <td>1040.870239</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           loss  mean_absolute_error  mean_squared_error     val_loss  \\\n",
       "0   1960.505538            11.085601         1960.495850  1977.193724   \n",
       "1   1909.706727            10.885015         1909.700684  1915.721155   \n",
       "2   1828.697132            10.612532         1828.684204  1853.169155   \n",
       "3   1744.994297            10.301882         1744.984497  1744.437534   \n",
       "4   1672.969164            10.100968         1672.969727  1719.620754   \n",
       "5   1642.198482            10.008043         1642.208374  1687.393910   \n",
       "6   1618.648786             9.920607         1618.653564  1645.547099   \n",
       "7   1600.134799             9.862710         1600.137573  1656.181159   \n",
       "8   1580.953250             9.798059         1580.948364  1629.672884   \n",
       "9   1564.923712             9.765280         1564.912354  1617.099227   \n",
       "10  1557.295057             9.756149         1557.296387  1604.847490   \n",
       "11  1533.137253             9.740894         1533.137085  1593.489502   \n",
       "12  1513.096974             9.730241         1513.074341  1566.101312   \n",
       "13  1496.476220             9.716362         1496.480225  1542.421586   \n",
       "14  1472.560089             9.662549         1472.560791  1515.027286   \n",
       "15  1445.129719             9.619605         1445.110474  1499.138709   \n",
       "16  1433.998351             9.569892         1433.998901  1501.031964   \n",
       "17  1418.675881             9.473996         1418.678223  1467.606539   \n",
       "18  1389.776983             9.431496         1389.778809  1478.381055   \n",
       "19  1369.985799             9.414393         1369.967285  1443.714888   \n",
       "20  1371.319403             9.401914         1371.323364  1432.826771   \n",
       "21  1344.497849             9.353391         1344.492676  1424.751464   \n",
       "22  1335.926158             9.328382         1335.918945  1405.113278   \n",
       "23  1324.774696             9.292337         1324.778076  1405.907752   \n",
       "24  1322.010429             9.273429         1322.016479  1376.995722   \n",
       "25  1305.528167             9.270911         1305.527832  1376.530576   \n",
       "26  1294.170035             9.269855         1294.171509  1365.404569   \n",
       "27  1277.990579             9.253692         1277.981323  1367.721230   \n",
       "28  1252.727570             9.226893         1252.740234  1292.737911   \n",
       "29  1207.353340             9.153671         1207.338135  1254.450771   \n",
       "..          ...                  ...                 ...          ...   \n",
       "70  1018.276246             8.733221         1018.272400  1068.270557   \n",
       "71  1009.440059             8.700762         1009.438110  1089.764413   \n",
       "72  1004.789436             8.681417         1004.779175  1088.496087   \n",
       "73  1003.010928             8.660819         1003.025391  1058.356513   \n",
       "74   998.833574             8.656103          998.831604  1074.967316   \n",
       "75  1000.553477             8.650024         1000.566162  1073.363059   \n",
       "76  1000.159576             8.644251         1000.147888  1054.486882   \n",
       "77   998.472123             8.645750          998.471436  1071.629961   \n",
       "78   996.705941             8.639237          996.711182  1063.637090   \n",
       "79   996.244009             8.636581          996.243591  1053.085399   \n",
       "80   988.786217             8.635191          988.784241  1064.350065   \n",
       "81   982.573304             8.614997          982.568237  1039.542201   \n",
       "82   976.315092             8.610019          976.320251  1045.099806   \n",
       "83   973.156490             8.607632          973.162476  1023.765564   \n",
       "84   967.550879             8.597527          967.540833  1048.205990   \n",
       "85   962.959775             8.586664          962.970947  1031.245019   \n",
       "86   968.239036             8.590590          968.245728  1046.636130   \n",
       "87   970.707476             8.598314          970.718079  1062.044761   \n",
       "88   972.070557             8.597642          972.057495  1037.197236   \n",
       "89   960.071002             8.592305          960.070435  1021.088386   \n",
       "90   958.631588             8.597425          958.624268  1036.237883   \n",
       "91   958.984170             8.603883          958.982971  1024.950887   \n",
       "92   957.046754             8.611216          957.044556  1022.887621   \n",
       "93   949.134043             8.608199          949.132812  1015.087136   \n",
       "94   953.743137             8.610863          953.746399  1022.570636   \n",
       "95   955.615272             8.617002          955.608643  1022.172815   \n",
       "96   953.865778             8.617057          953.876099  1004.477572   \n",
       "97   951.716290             8.619240          951.716797  1023.319044   \n",
       "98   957.484109             8.630308          957.485413  1015.595881   \n",
       "99   954.182760             8.634252          954.193115  1040.874896   \n",
       "\n",
       "    val_mean_absolute_error  val_mean_squared_error  epoch  \n",
       "0                 10.932296             1977.186646      0  \n",
       "1                 10.794977             1915.719360      1  \n",
       "2                 10.450208             1853.172729      2  \n",
       "3                 10.109297             1744.441040      3  \n",
       "4                 10.042290             1719.632080      4  \n",
       "5                  9.925940             1687.396729      5  \n",
       "6                  9.809487             1645.541016      6  \n",
       "7                  9.924092             1656.178833      7  \n",
       "8                  9.983445             1629.671753      8  \n",
       "9                  9.930725             1617.101196      9  \n",
       "10                 9.814301             1604.841187     10  \n",
       "11                 9.635554             1593.489380     11  \n",
       "12                 9.757917             1566.110840     12  \n",
       "13                 9.647374             1542.425415     13  \n",
       "14                 9.536309             1515.022461     14  \n",
       "15                 9.542570             1499.144043     15  \n",
       "16                 9.638397             1501.036011     16  \n",
       "17                 9.334167             1467.598633     17  \n",
       "18                 9.551398             1478.378052     18  \n",
       "19                 9.527734             1443.714966     19  \n",
       "20                 9.755646             1432.823730     20  \n",
       "21                 9.368645             1424.756226     21  \n",
       "22                 9.241011             1405.113037     22  \n",
       "23                 9.261625             1405.908936     23  \n",
       "24                 9.216565             1376.997070     24  \n",
       "25                 9.561979             1376.529297     25  \n",
       "26                 9.298976             1365.399170     26  \n",
       "27                 9.498814             1367.723999     27  \n",
       "28                 9.258724             1292.742798     28  \n",
       "29                 9.032564             1254.444946     29  \n",
       "..                      ...                     ...    ...  \n",
       "70                 8.540742             1068.274048     70  \n",
       "71                 9.191953             1089.763306     71  \n",
       "72                 8.803307             1088.495361     72  \n",
       "73                 8.506585             1058.355591     73  \n",
       "74                 8.868889             1074.965210     74  \n",
       "75                 8.878466             1073.371216     75  \n",
       "76                 8.450307             1054.481323     76  \n",
       "77                 8.781075             1071.635498     77  \n",
       "78                 8.563958             1063.634033     78  \n",
       "79                 8.538595             1053.080444     79  \n",
       "80                 8.491701             1064.347168     80  \n",
       "81                 8.508296             1039.540405     81  \n",
       "82                 8.860886             1045.094849     82  \n",
       "83                 8.355792             1023.769104     83  \n",
       "84                 8.509310             1048.202026     84  \n",
       "85                 8.476836             1031.248169     85  \n",
       "86                 8.602034             1046.637939     86  \n",
       "87                 8.865154             1062.044922     87  \n",
       "88                 8.469958             1037.197388     88  \n",
       "89                 8.370193             1021.082642     89  \n",
       "90                 8.892288             1036.236816     90  \n",
       "91                 8.671714             1024.954590     91  \n",
       "92                 8.443459             1022.887634     92  \n",
       "93                 8.575620             1015.081116     93  \n",
       "94                 8.395283             1022.568054     94  \n",
       "95                 8.511609             1022.174072     95  \n",
       "96                 8.596503             1004.481079     96  \n",
       "97                 8.519594             1023.314087     97  \n",
       "98                 8.405902             1015.600586     98  \n",
       "99                 8.950229             1040.870239     99  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 64)                512       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 577\n",
      "Trainable params: 577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch: 0, loss:16776144114472384.0000,  mean_absolute_error:4861550.5000,  mean_squared_error:16763241250160640.0000,  val_loss:513169574993.0494,  val_mean_absolute_error:111827.4062,  val_mean_squared_error:513171947520.0000,  \n",
      "..............."
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()\n",
    "\n",
    "# example_batch = normed_train_data[:10]\n",
    "# example_result = model.predict(example_batch)\n",
    "# example_result\n",
    "\n",
    "EPOCHS = 40\n",
    "\n",
    "# filepath=\"ckpoints.hdf5\"\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "# callbacks_list = [checkpoint]\n",
    "\n",
    "history = model.fit(\n",
    "  train_dataset, train_labels,\n",
    "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
    "  callbacks=[tfdocs.modeling.EpochDots()])\n",
    "#     callbacks = callbacks_list)\n",
    "\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tf.keras.utils.plot_model(model, to_file='model.png')\n",
    "\n",
    "# plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)\n",
    "\n",
    "\n",
    "# loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=2)\n",
    "preds = model.predict(test_dataset)\n",
    "rmse = mean_squared_error(test_labels, preds)\n",
    "rmae = mean_absolute_error(test_labels, preds)\n",
    "r2 = r2_score(test_labels, preds)\n",
    "print(\"MSE, MAE, r2: %f %f %f\" % (rmse, rmae, r2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "#activation(dot(input, kernel) + bias)\n",
    "for layer in model.get_weights():\n",
    "    s = 'W' if (i % 2 == 0) else 'B'\n",
    "    print('val l%d%s = Seq(%s)' % (1+i//2, s, ','.join(['%f.to[T]' % x for x in layer.flatten()])))\n",
    "#     print('Layer %d' % i)\n",
    "#     print(layer)\n",
    "    i =  i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
