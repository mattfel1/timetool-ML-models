{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow_lattice as tfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from common.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Import helpers\n",
    "import import_ipynb\n",
    "from common import buildDatasetForLattice\n",
    "from common import scaleVolume\n",
    "from common import extractLatticeWeights\n",
    "from common import dropColumns\n",
    "from common import filterBad\n",
    "from common import splitDataset\n",
    "from common import normDataset\n",
    "from common import evaluatePerf\n",
    "from common import evaluateCustom\n",
    "from common import extractXGWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rejected 6196746 points (56.847699%)\n"
     ]
    }
   ],
   "source": [
    "only_use_strong = 54\n",
    "\n",
    "dataset, columns = buildDatasetForLattice()\n",
    "dataset = filterBad(dataset, only_use_strong)\n",
    "train_dataset, test_dataset, train_labels, test_labels = splitDataset(dataset, 0.2)\n",
    "train_stats = train_dataset.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(['row'], axis=1)\n",
    "columns = [x for x in columns if x != 'row']\n",
    "train_dataset, test_dataset, train_labels, test_labels = splitDataset(dataset, 0.2)\n",
    "train_stats = train_dataset.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 40. 102. 159. 206. 261. 321. 405. 629.]\n",
      "[0.0000e+00 0.0000e+00 3.0000e+00 1.2000e+01 3.6000e+01 1.1200e+02\n",
      " 4.8000e+02 1.7355e+04]\n"
     ]
    }
   ],
   "source": [
    "quartiles = np.percentile(dataset['rising_idx'], np.linspace(0,99,8))\n",
    "print(quartiles)\n",
    "quartiles = np.percentile(dataset['first_val'], np.linspace(0,99,8))\n",
    "print(quartiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildLattice(num_keypoints, lattice_size, columns):\n",
    "    # Use ParallelCombination helper layer to group togehter calibration layers\n",
    "    # which have to be executed in paralel in order to be able to use Sequential\n",
    "    # model. Alternatively you can use functional API.\n",
    "    combined_calibrators = tfl.layers.ParallelCombination()\n",
    "\n",
    "    # Configure calibration layers for every feature:\n",
    "\n",
    "    for ft in columns:\n",
    "        kpts = np.percentile(dataset[ft], np.linspace(0,99,num_keypoints))\n",
    "        for i in range(1,len(kpts)):\n",
    "            while kpts[i] <= kpts[i-1]:\n",
    "                kpts[i] = kpts[i] + 1\n",
    "        calibrator = tfl.layers.PWLCalibration(\n",
    "            # Every PWLCalibration layer must have keypoints of piecewise linear\n",
    "            # function specified. Easiest way to specify them is to uniformly cover\n",
    "            # entire input range by using numpy.linspace().\n",
    "            input_keypoints=kpts,\n",
    "#             input_keypoints=np.linspace(dataset[ft].min(),\n",
    "#                                       dataset[ft].max(),\n",
    "#                                       num=num_keypoints),\n",
    "        # You need to ensure that input keypoints have same dtype as layer input.\n",
    "        # You can do it by setting dtype here or by providing keypoints in such\n",
    "        # format which will be converted to deisred tf.dtype by default.\n",
    "        dtype=tf.float32,\n",
    "        # Output range must correspond to expected lattice input range.\n",
    "        output_min=0.0,\n",
    "        output_max=lattice_size - 1.0,\n",
    "        monotonicity='increasing')\n",
    "        combined_calibrators.append(calibrator)\n",
    "\n",
    "    # Create Lattice layer to nonlineary fuse output of calibrators. Don't forget\n",
    "    # to specify monotonicity 'increasing' for any dimension which calibrator is\n",
    "    # monotonic regardless of monotonicity direction of calibrator. This includes\n",
    "    # partial monotonicity of CategoricalCalibration layer.\n",
    "    lattice = tfl.layers.Lattice(\n",
    "      lattice_sizes=[lattice_size for _ in columns],\n",
    "      monotonicities=['increasing' if (ft == 'rising_idx' or ft == 'falling_idx') else 'none' for x in columns],\n",
    "      output_min=dataset['delay'].min(),\n",
    "      output_max=dataset['delay'].max())\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    # We have just 2 layer as far as Sequential model is concerned.\n",
    "    # PWLConcatenate layer takes care of grouping calibrators.\n",
    "    model.add(combined_calibrators)\n",
    "    model.add(lattice)\n",
    "    model.compile(loss=keras.losses.mean_squared_error,\n",
    "                optimizer=keras.optimizers.Adagrad(learning_rate=80.0))\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainLattice(model, modelName, cols, epochs):\n",
    "    \n",
    "    features = train_dataset[cols].values.astype(np.float32)\n",
    "    target = train_labels.values.astype(np.float32)\n",
    "\n",
    "    checkpoint = ModelCheckpoint('./' + modelName, monitor='val_accuracy', verbose=0, save_best_only=True, mode='max')\n",
    "    model.fit(features,\n",
    "            target,\n",
    "            batch_size=32,\n",
    "            epochs=epochs,\n",
    "            validation_split=0.05,\n",
    "            shuffle=False,\n",
    "            callbacks=[checkpoint])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3574936 samples, validate on 188155 samples\n",
      "WARNING:tensorflow:From /home/mattfel/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/mattfel/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/adagrad.py:105: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Epoch 1/30\n",
      "3574912/3574936 [============================>.] - ETA: 0s - loss: 433972.6638WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 960s 269us/sample - loss: 433972.1551 - val_loss: 258578.4270\n",
      "Epoch 2/30\n",
      "3574624/3574936 [============================>.] - ETA: 0s - loss: 252335.5424WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 892s 249us/sample - loss: 252330.2396 - val_loss: 76685.7327\n",
      "Epoch 3/30\n",
      "3574880/3574936 [============================>.] - ETA: 0s - loss: 227914.3050WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 660s 185us/sample - loss: 227911.8262 - val_loss: 55139.8669\n",
      "Epoch 4/30\n",
      "3574752/3574936 [============================>.] - ETA: 0s - loss: 209007.3878WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 908s 254us/sample - loss: 209001.3135 - val_loss: 222679.6514\n",
      "Epoch 5/30\n",
      "3574848/3574936 [============================>.] - ETA: 0s - loss: 194181.8395WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 893s 250us/sample - loss: 194178.7305 - val_loss: 46571.2440\n",
      "Epoch 6/30\n",
      "3574816/3574936 [============================>.] - ETA: 0s - loss: 183012.4647WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 860s 241us/sample - loss: 183009.4599 - val_loss: 52384.5168\n",
      "Epoch 7/30\n",
      "3574912/3574936 [============================>.] - ETA: 0s - loss: 173086.5408WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 872s 244us/sample - loss: 173086.1595 - val_loss: 83231.7254\n",
      "Epoch 8/30\n",
      "3574816/3574936 [============================>.] - ETA: 0s - loss: 165112.7174WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 880s 246us/sample - loss: 165112.4088 - val_loss: 70701.6805\n",
      "Epoch 9/30\n",
      "3574784/3574936 [============================>.] - ETA: 0s - loss: 158758.6088WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 899s 252us/sample - loss: 158756.3146 - val_loss: 65522.7106\n",
      "Epoch 10/30\n",
      "3574752/3574936 [============================>.] - ETA: 0s - loss: 152841.8617WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 872s 244us/sample - loss: 152840.6183 - val_loss: 62592.5766\n",
      "Epoch 11/30\n",
      "3574880/3574936 [============================>.] - ETA: 0s - loss: 148745.4402WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 860s 240us/sample - loss: 148743.9721 - val_loss: 60929.5791\n",
      "Epoch 12/30\n",
      "3574784/3574936 [============================>.] - ETA: 0s - loss: 143542.1670WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 845s 236us/sample - loss: 143541.6167 - val_loss: 63706.0129\n",
      "Epoch 13/30\n",
      "3574912/3574936 [============================>.] - ETA: 0s - loss: 140755.5027WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 860s 241us/sample - loss: 140754.8393 - val_loss: 45012.9562\n",
      "Epoch 14/30\n",
      "3574848/3574936 [============================>.] - ETA: 0s - loss: 137898.8384WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 872s 244us/sample - loss: 137898.3141 - val_loss: 126428.5400\n",
      "Epoch 15/30\n",
      "3574848/3574936 [============================>.] - ETA: 0s - loss: 134065.2874WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 860s 241us/sample - loss: 134064.1724 - val_loss: 62732.1065\n",
      "Epoch 16/30\n",
      "3574688/3574936 [============================>.] - ETA: 0s - loss: 132111.1037WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 799s 223us/sample - loss: 132110.7594 - val_loss: 58696.2519\n",
      "Epoch 17/30\n",
      "3574656/3574936 [============================>.] - ETA: 0s - loss: 129124.3028WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 797s 223us/sample - loss: 129123.3777 - val_loss: 69306.4742\n",
      "Epoch 18/30\n",
      "3574656/3574936 [============================>.] - ETA: 0s - loss: 127951.9031WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 556s 156us/sample - loss: 127947.8040 - val_loss: 73446.6770\n",
      "Epoch 19/30\n",
      "3574912/3574936 [============================>.] - ETA: 0s - loss: 124967.5238WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 519s 145us/sample - loss: 124967.0088 - val_loss: 53563.8286\n",
      "Epoch 20/30\n",
      "3574816/3574936 [============================>.] - ETA: 0s - loss: 122339.2129WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 502s 140us/sample - loss: 122340.1665 - val_loss: 29414.7264\n",
      "Epoch 21/30\n",
      "3574624/3574936 [============================>.] - ETA: 0s - loss: 120750.9743WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 497s 139us/sample - loss: 120753.4858 - val_loss: 53492.4000\n",
      "Epoch 22/30\n",
      "3574496/3574936 [============================>.] - ETA: 0s - loss: 119359.9958WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 492s 138us/sample - loss: 119360.9236 - val_loss: 67914.3967\n",
      "Epoch 23/30\n",
      "3574656/3574936 [============================>.] - ETA: 0s - loss: 117358.2917WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 490s 137us/sample - loss: 117356.8664 - val_loss: 43114.2266\n",
      "Epoch 24/30\n",
      "3574592/3574936 [============================>.] - ETA: 0s - loss: 116009.5948WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 490s 137us/sample - loss: 116009.3728 - val_loss: 28265.3453\n",
      "Epoch 25/30\n",
      "3574720/3574936 [============================>.] - ETA: 0s - loss: 114560.2723WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 490s 137us/sample - loss: 114561.9539 - val_loss: 26265.4463\n",
      "Epoch 26/30\n",
      "3574752/3574936 [============================>.] - ETA: 0s - loss: 112958.1380WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 489s 137us/sample - loss: 112956.5184 - val_loss: 43153.6431\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3574752/3574936 [============================>.] - ETA: 0s - loss: 111259.1199WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 489s 137us/sample - loss: 111259.3243 - val_loss: 48007.3089\n",
      "Epoch 28/30\n",
      "3574496/3574936 [============================>.] - ETA: 0s - loss: 110672.5552WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 490s 137us/sample - loss: 110671.2357 - val_loss: 30149.1325\n",
      "Epoch 29/30\n",
      "3574656/3574936 [============================>.] - ETA: 0s - loss: 108629.5487WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 489s 137us/sample - loss: 108628.9413 - val_loss: 44215.5985\n",
      "Epoch 30/30\n",
      "3574528/3574936 [============================>.] - ETA: 0s - loss: 107510.7938WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 489s 137us/sample - loss: 107511.0723 - val_loss: 44469.3270\n",
      "MSE, MAE, r2: 44672.205543,174.931575,0.957360\n",
      "--------------------------------\n",
      "TBD :)\n",
      "--------------------------------\n",
      "Train on 3574936 samples, validate on 188155 samples\n",
      "Epoch 1/30\n",
      "3574624/3574936 [============================>.] - ETA: 0s - loss: 106489.4749WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 509s 142us/sample - loss: 106487.4271 - val_loss: 47695.4210\n",
      "Epoch 2/30\n",
      "3574848/3574936 [============================>.] - ETA: 0s - loss: 105248.6654WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 489s 137us/sample - loss: 105247.8367 - val_loss: 25526.3493\n",
      "Epoch 3/30\n",
      "3574880/3574936 [============================>.] - ETA: 0s - loss: 103637.3717WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 490s 137us/sample - loss: 103637.3349 - val_loss: 48917.4212\n",
      "Epoch 4/30\n",
      "3574880/3574936 [============================>.] - ETA: 0s - loss: 102697.4019WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 489s 137us/sample - loss: 102696.1805 - val_loss: 20493.0457\n",
      "Epoch 5/30\n",
      "3574752/3574936 [============================>.] - ETA: 0s - loss: 101669.8078WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 491s 137us/sample - loss: 101671.2793 - val_loss: 75010.3470\n",
      "Epoch 6/30\n",
      "3574528/3574936 [============================>.] - ETA: 0s - loss: 101586.1761WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 492s 138us/sample - loss: 101594.0209 - val_loss: 25219.4968\n",
      "Epoch 7/30\n",
      "3574784/3574936 [============================>.] - ETA: 0s - loss: 100013.1120WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 492s 138us/sample - loss: 100012.3335 - val_loss: 36295.1673\n",
      "Epoch 8/30\n",
      "3574816/3574936 [============================>.] - ETA: 0s - loss: 98091.3082WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 492s 138us/sample - loss: 98091.6531 - val_loss: 62484.9844\n",
      "Epoch 9/30\n",
      "3574816/3574936 [============================>.] - ETA: 0s - loss: 97681.1208WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 492s 138us/sample - loss: 97680.4766 - val_loss: 31861.3318\n",
      "Epoch 10/30\n",
      "3574880/3574936 [============================>.] - ETA: 0s - loss: 97696.5545WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 492s 138us/sample - loss: 97696.9301 - val_loss: 70065.1090\n",
      "Epoch 11/30\n",
      "3574752/3574936 [============================>.] - ETA: 0s - loss: 95511.2919WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 492s 138us/sample - loss: 95511.3492 - val_loss: 31070.1276\n",
      "Epoch 12/30\n",
      "3574688/3574936 [============================>.] - ETA: 0s - loss: 96247.5758WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 492s 138us/sample - loss: 96247.6696 - val_loss: 40064.1162\n",
      "Epoch 13/30\n",
      "3574752/3574936 [============================>.] - ETA: 0s - loss: 93496.3308WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 492s 138us/sample - loss: 93496.3898 - val_loss: 43414.0165\n",
      "Epoch 14/30\n",
      "3574592/3574936 [============================>.] - ETA: 0s - loss: 94386.7321WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 493s 138us/sample - loss: 94386.2374 - val_loss: 44372.2277\n",
      "Epoch 15/30\n",
      "3574848/3574936 [============================>.] - ETA: 0s - loss: 93081.7193WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 492s 138us/sample - loss: 93082.0705 - val_loss: 54840.2423\n",
      "Epoch 16/30\n",
      "3574656/3574936 [============================>.] - ETA: 0s - loss: 92668.4470WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 493s 138us/sample - loss: 92670.2541 - val_loss: 45589.0487\n",
      "Epoch 17/30\n",
      "3574752/3574936 [============================>.] - ETA: 0s - loss: 92865.1894WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 492s 138us/sample - loss: 92865.9226 - val_loss: 58160.8210\n",
      "Epoch 18/30\n",
      "3574784/3574936 [============================>.] - ETA: 0s - loss: 89882.7983WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 492s 138us/sample - loss: 89883.9341 - val_loss: 45054.6390\n",
      "Epoch 19/30\n",
      "3574848/3574936 [============================>.] - ETA: 0s - loss: 90775.9840WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 492s 138us/sample - loss: 90775.9760 - val_loss: 39864.8600\n",
      "Epoch 20/30\n",
      "3574784/3574936 [============================>.] - ETA: 0s - loss: 90580.2421WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 493s 138us/sample - loss: 90580.8350 - val_loss: 59984.6565\n",
      "Epoch 21/30\n",
      "3574752/3574936 [============================>.] - ETA: 0s - loss: 88080.3923WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 493s 138us/sample - loss: 88079.8760 - val_loss: 39093.6880\n",
      "Epoch 22/30\n",
      "3574560/3574936 [============================>.] - ETA: 0s - loss: 90042.3508WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 494s 138us/sample - loss: 90039.8550 - val_loss: 48039.8959\n",
      "Epoch 23/30\n",
      "3574784/3574936 [============================>.] - ETA: 0s - loss: 86027.4204WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 493s 138us/sample - loss: 86029.4809 - val_loss: 42099.2677\n",
      "Epoch 24/30\n",
      "3574624/3574936 [============================>.] - ETA: 0s - loss: 88208.3958WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 493s 138us/sample - loss: 88210.2684 - val_loss: 51839.5040\n",
      "Epoch 25/30\n",
      "3574592/3574936 [============================>.] - ETA: 0s - loss: 86277.7459WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3574936/3574936 [==============================] - 493s 138us/sample - loss: 86276.8257 - val_loss: 59621.8285\n",
      "Epoch 26/30\n",
      "3574880/3574936 [============================>.] - ETA: 0s - loss: 86202.5054WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 492s 138us/sample - loss: 86201.6092 - val_loss: 56609.9027\n",
      "Epoch 27/30\n",
      "3574528/3574936 [============================>.] - ETA: 0s - loss: 84776.9518WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 492s 138us/sample - loss: 84773.2114 - val_loss: 27597.8248\n",
      "Epoch 28/30\n",
      "3574912/3574936 [============================>.] - ETA: 0s - loss: 83945.8082WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "3574936/3574936 [==============================] - 493s 138us/sample - loss: 83945.4347 - val_loss: 51137.0456\n",
      "Epoch 30/30\n",
      "1737760/3574936 [=============>................] - ETA: 4:07 - loss: 82473.1917"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3528832/3574936 [============================>.] - ETA: 6s - loss: 82844.1573"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_perf = True\n",
    "load_prior_model = True\n",
    "train_model = True\n",
    "strong_data_sfx = \"_strong\" if (only_use_strong > 0) else \"\"\n",
    "\n",
    "\n",
    "\n",
    "# Hypercube_16_2 = buildLattice(16,2,columns[:-1])\n",
    "# if (load_prior_model): \n",
    "#     Hypercube_16_2.build((None,4,))\n",
    "#     Hypercube_16_2.load_weights('./Hypercube_16_2' + strong_data_sfx) #load\n",
    "# if (train_model): \n",
    "#     Hypercube_16_2 = trainLattice(Hypercube_16_2,'Hypercube_16_2' + strong_data_sfx,columns[:-1], 30) #train\n",
    "#     Hypercube_16_2.save('./Hypercube_16_2' + strong_data_sfx)\n",
    "# preds = Hypercube_16_2.predict(test_dataset.values.astype(np.float32))\n",
    "# if (show_perf): evaluatePerf(test_labels, preds)\n",
    "# print('--------------------------------')\n",
    "# extractLatticeWeights(Hypercube_16_2, 'Hypercube_16_2' + strong_data_sfx)\n",
    "# print('--------------------------------')\n",
    "\n",
    "\n",
    "Hypercube_8_4 = buildLattice(8,4,columns[:-1])\n",
    "if (load_prior_model): \n",
    "    Hypercube_8_4.build((None,4,))\n",
    "    Hypercube_8_4.load_weights('./Hypercube_8_4' + strong_data_sfx) #load\n",
    "if (train_model): \n",
    "    Hypercube_8_4 = trainLattice(Hypercube_16_2,'Hypercube_8_4' + strong_data_sfx,columns[:-1], 30) #train\n",
    "    Hypercube_8_4.save('./Hypercube_8_4' + strong_data_sfx)\n",
    "preds = Hypercube_8_4.predict(test_dataset.values.astype(np.float32))\n",
    "if (show_perf): evaluatePerf(test_labels, preds)\n",
    "print('--------------------------------')\n",
    "extractLatticeWeights(Hypercube_8_4, 'Hypercube_8_4' + strong_data_sfx)\n",
    "print('--------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = Hypercube_8_4.predict(test_dataset.values.astype(np.float32))\n",
    "if (show_perf): evaluatePerf(test_labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
