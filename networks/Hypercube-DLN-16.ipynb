{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_lattice as tfl\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from common.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Import helpers\n",
    "import import_ipynb\n",
    "from common import buildDatasetForLattice\n",
    "from common import scaleVolume\n",
    "from common import extractLatticeWeights\n",
    "from common import dropColumns\n",
    "from common import filterBad\n",
    "from common import splitDataset\n",
    "from common import normDataset\n",
    "from common import evaluatePerf\n",
    "from common import evaluateCustom\n",
    "from common import extractXGWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rejected 2017073 points (18.505442%)\n"
     ]
    }
   ],
   "source": [
    "dataset, columns = buildDatasetForLattice()\n",
    "dataset = filterBad(dataset)\n",
    "train_dataset, test_dataset, train_labels, test_labels = splitDataset(dataset, 0.2)\n",
    "train_stats = train_dataset.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_dataset = dataset.copy()\n",
    "col = preprocessed_dataset.first_val\n",
    "preprocessed_dataset.first_val = np.log(col + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_initializers = {\n",
    "    'row': \"quantile\", 'rising_idx': \"quantile\", 'falling_idx': \"quantile\", 'first_val': \"uniform\", 'last_val': \"uniform\"\n",
    "}\n",
    "monotonicities = {\n",
    "    \"rising_idx\": -1,\n",
    "    \"falling_idx\": -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildLattice(num_keypoints, lattice_size, columns, num_lattices):\n",
    "    inputs = [keras.layers.Input(shape=[1]) for _ in columns]\n",
    "    combined_calibrators = []\n",
    "    for inpt, ft in zip(inputs, columns):\n",
    "        if ft != \"row\":\n",
    "            if kp_initializers[ft] == \"quantile\":\n",
    "                quantile_vals = [i/(num_keypoints - 1.0) for i in range(num_keypoints)]\n",
    "                keypoints = dataset[ft].quantile(quantile_vals).values\n",
    "            if kp_initializers[ft] == \"uniform\":\n",
    "                keypoints = np.linspace(preprocessed_dataset[ft].min(), preprocessed_dataset[ft].max(), num=num_keypoints)\n",
    "\n",
    "            calibrator = tfl.layers.PWLCalibration(\n",
    "                input_keypoints=keypoints, dtype=tf.float32, output_min=0.0, output_max=lattice_size - 1.0,\n",
    "                kernel_regularizer = [(\"wrinkle\", 1e-4, 1e-5)],\n",
    "                monotonicity=monotonicities.get(ft, 0),\n",
    "                units = num_lattices\n",
    "            )(inpt)\n",
    "        else:\n",
    "            # row is categorical\n",
    "            calibrator = tfl.layers.CategoricalCalibration(\n",
    "                num_buckets=preprocessed_dataset[ft].nunique(),\n",
    "                output_min = 0.0,\n",
    "                output_max = lattice_size - 1.0,\n",
    "                units = num_lattices\n",
    "            )(inpt)\n",
    "        combined_calibrators.append(calibrator)\n",
    "    lattices = []\n",
    "    for i in range(num_lattices):\n",
    "        lattice_inputs = []\n",
    "        for col in range(len(columns)):\n",
    "            lattice_inputs.append(\n",
    "                keras.backend.transpose(\n",
    "                    keras.backend.gather(\n",
    "                        keras.backend.transpose(combined_calibrators[col]), [i])))\n",
    "        lattice = tfl.layers.Lattice(\n",
    "            lattice_sizes=[lattice_size for _ in columns],\n",
    "            monotonicities=['increasing' if (ft == 'rising_idx' or ft == 'falling_idx') else 'none' for x in columns],\n",
    "            output_min=dataset['delay'].min(),\n",
    "            output_max=dataset['delay'].max())(keras.layers.concatenate(lattice_inputs))\n",
    "        lattices.append(lattice)\n",
    "    \n",
    "    if num_lattices == 1:\n",
    "        model = keras.models.Model(inputs=inputs, outputs=lattices[0])\n",
    "    else:\n",
    "        model = keras.models.Model(inputs=inputs, outputs=tfl.layers.Linear(\n",
    "            num_input_dims=num_lattices, normalization_order=1,\n",
    "            kernel_regularizer=keras.regularizers.l1(0.01))(keras.layers.concatenate(lattices)))\n",
    "    model.compile(loss=keras.losses.mean_absolute_error,\n",
    "                optimizer=keras.optimizers.Adam(), metrics=[\"mse\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainLattice(model, cols, epochs):\n",
    "    features = [preprocessed_dataset[col].values for col in cols]\n",
    "    target = preprocessed_dataset[\"delay\"]\n",
    "\n",
    "    history = model.fit(features,\n",
    "            target,\n",
    "            batch_size=32,\n",
    "            epochs=epochs,\n",
    "            validation_split=0.2,\n",
    "            shuffle=True, workers=32, use_multiprocessing=True)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Hypercube_8_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fd9438fb20ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Hypercube_8_2 = buildLattice(num_kps, 2, columns[:-1], num_lattices)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainLattice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHypercube_8_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mHypercube_8_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Hypercube_8_2' is not defined"
     ]
    }
   ],
   "source": [
    "show_perf = True\n",
    "train_model = True\n",
    "\n",
    "num_kps = 16\n",
    "num_lattices = 16\n",
    "model_path = f\"./Hypercube_{num_kps}_{num_lattices}\"\n",
    "\n",
    "# Hypercube_8_2 = buildLattice(num_kps, 2, columns[:-1], num_lattices)\n",
    "history = trainLattice(Hypercube_8_2,columns[:-1], 40)\n",
    "Hypercube_8_2.save(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
