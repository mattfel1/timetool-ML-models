{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.output_scroll { height: 100em; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import os\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "from IPython.display import display\n",
    "# boston = load_boston()\n",
    "import pandas as pd\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 100em; }</style>\"))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from common.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Import helpers\n",
    "import import_ipynb\n",
    "from common import buildDataset\n",
    "from common import scaleVolume\n",
    "from common import filterBad\n",
    "from common import splitDataset\n",
    "from common import dropColumns\n",
    "from common import normDataset\n",
    "from common import evaluatePerf\n",
    "from common import evaluateCustom\n",
    "from common import extractXGWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rejected 6196563 points (56.849770%)\n"
     ]
    }
   ],
   "source": [
    "only_use_strong = 54\n",
    "\n",
    "dataset, columns = buildDataset()\n",
    "dataset = filterBad(dataset, only_use_strong)\n",
    "dataset = scaleVolume(dataset, 4096)\n",
    "dataset, columns = dropColumns(dataset, ['fileId'])\n",
    "train_dataset, test_dataset, train_labels, test_labels = splitDataset(dataset, 0.1)\n",
    "train_stats = train_dataset.describe().transpose()\n",
    "\n",
    "# print(train_dataset)\n",
    "# print(normed_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildXG(alpha, colsampbytree, base_score, lr, lmbda, num_trees, max_depth):\n",
    "    return xgb.XGBRegressor(objective ='reg:squarederror', base_score = base_score, \n",
    "                              colsample_bytree = colsampbytree, learning_rate = lr,\n",
    "                              max_depth = max_depth, alpha = alpha, n_estimators = num_trees, reg_lambda = lmbda)\n",
    "\n",
    "def trainXG(xg_reg):\n",
    "    # xg_reg.print_evaluation()\n",
    "    xg_reg.fit(train_dataset,train_labels)\n",
    "    return xg_reg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE, MAE, r2: 1420.118693,26.236022,0.998644\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "MSE, MAE, r2: 858.499939,17.507861,0.999180\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "MSE, MAE, r2: 780.513307,16.385792,0.999255\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "MSE, MAE, r2: 794.024493,16.670699,0.999242\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "MSE, MAE, r2: 542.114481,12.631137,0.999482\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "MSE, MAE, r2: 857.042352,17.229776,0.999182\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "MSE, MAE, r2: 555.423423,12.826452,0.999470\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "MSE, MAE, r2: 421.224907,10.942806,0.999598\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "MSE, MAE, r2: 347.493408,9.870572,0.999668\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "MSE, MAE, r2: 678.364573,15.182954,0.999352\n",
      "--------------------------------\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "show_perf = True\n",
    "train_model = True\n",
    "load_previous_model = False\n",
    "strong_data_sfx = \"_strong\" if (only_use_strong > 0) else \"\"\n",
    "\n",
    "# XGBoost_xxx_yyy = buildXG(10, 0.3, 0.5, 0.9, 2, xxx, yyy)\n",
    "# # Either train or load weights\n",
    "# if (load_previous_model):\n",
    "#     XGBoost_xxx_yyy.load_model('./XGBoost_xxx_yyy') #load\n",
    "# if (train_model): \n",
    "#     XGBoost_xxx_yyy = trainXG(XGBoost_xxx_yyy) #train\n",
    "#     XGBoost_xxx_yyy.save_model('./XGBoost_xxx_yyy')\n",
    "# preds = XGBoost_xxx_yyy.predict(test_dataset)\n",
    "# if (show_perf): evaluatePerf(test_labels, preds)\n",
    "# print('--------------------------------')\n",
    "# extractXGWeights(XGBoost_xxx_yyy, 'XGBoost_xxx_yyy', yyy)\n",
    "# print('--------------------------------')\n",
    "\n",
    "extractXGWeights_ = extractXGWeights\n",
    "extractXGWeights = lambda *args: None\n",
    "\n",
    "XGBoost_10_5 = buildXG(10, 0.3, 0.5, 0.9, 2, 10, 5)\n",
    "# Either train or load weights\n",
    "if (load_previous_model):\n",
    "    XGBoost_10_5.load_model('./XGBoost_10_5' + strong_data_sfx) #load\n",
    "if (train_model): \n",
    "    XGBoost_10_5 = trainXG(XGBoost_10_5) #train\n",
    "    XGBoost_10_5.save_model('./XGBoost_10_5' + strong_data_sfx)\n",
    "preds = XGBoost_10_5.predict(test_dataset)\n",
    "if (show_perf): evaluatePerf(test_labels, preds)\n",
    "print('--------------------------------')\n",
    "extractXGWeights(XGBoost_10_5, 'XGBoost_10_5' + strong_data_sfx, 5)\n",
    "print('--------------------------------')\n",
    "\n",
    "\n",
    "XGBoost_20_5 = buildXG(10, 0.3, 0.5, 0.9, 2, 20, 5)\n",
    "# Either train or load weights\n",
    "if (train_model): XGBoost_20_5 = trainXG(XGBoost_20_5) #train\n",
    "else: XGBoost_20_5.load_model('./XGBoost_20_5' + strong_data_sfx) #load\n",
    "# Save weights\n",
    "XGBoost_20_5.save_model('./XGBoost_20_5' + strong_data_sfx)\n",
    "preds = XGBoost_20_5.predict(test_dataset)\n",
    "if (show_perf): evaluatePerf(test_labels, preds)\n",
    "print('--------------------------------')\n",
    "extractXGWeights(XGBoost_20_5, 'XGBoost_20_5' + strong_data_sfx, 5)\n",
    "print('--------------------------------')\n",
    "\n",
    "\n",
    "XGBoost_25_5 = buildXG(10, 0.3, 0.5, 0.9, 2, 25, 5)\n",
    "# Either train or load weights\n",
    "if (train_model): XGBoost_25_5 = trainXG(XGBoost_25_5) #train\n",
    "else: XGBoost_25_5.load_model('./XGBoost_25_5' + strong_data_sfx) #load\n",
    "# Save weights\n",
    "XGBoost_25_5.save_model('./XGBoost_25_5' + strong_data_sfx)\n",
    "preds = XGBoost_25_5.predict(test_dataset)\n",
    "if (show_perf): evaluatePerf(test_labels, preds)\n",
    "print('--------------------------------')\n",
    "extractXGWeights(XGBoost_25_5, 'XGBoost_25_5' + strong_data_sfx, 5)\n",
    "print('--------------------------------')\n",
    "\n",
    "\n",
    "\n",
    "XGBoost_10_6 = buildXG(10, 0.3, 0.5, 0.9, 2, 10, 6)\n",
    "# Either train or load weights\n",
    "if (train_model): XGBoost_10_6 = trainXG(XGBoost_10_6) #train\n",
    "else: XGBoost_10_6.load_model('./XGBoost_10_6' + strong_data_sfx) #load\n",
    "# Save weights\n",
    "XGBoost_10_6.save_model('./XGBoost_10_6' + strong_data_sfx)\n",
    "preds = XGBoost_10_6.predict(test_dataset)\n",
    "if (show_perf): evaluatePerf(test_labels, preds)\n",
    "print('--------------------------------')\n",
    "extractXGWeights(XGBoost_10_6, 'XGBoost_10_6' + strong_data_sfx, 6)\n",
    "print('--------------------------------')\n",
    "\n",
    "\n",
    "\n",
    "XGBoost_20_6 = buildXG(10, 0.3, 0.5, 0.9, 2, 20, 6)\n",
    "# Either train or load weights\n",
    "if (train_model): XGBoost_20_6 = trainXG(XGBoost_20_6) #train\n",
    "else: XGBoost_20_6.load_model('./XGBoost_20_6' + strong_data_sfx) #load\n",
    "# Save weights\n",
    "XGBoost_20_6.save_model('./XGBoost_20_6' + strong_data_sfx)\n",
    "preds = XGBoost_20_6.predict(test_dataset)\n",
    "if (show_perf): evaluatePerf(test_labels, preds)\n",
    "print('--------------------------------')\n",
    "extractXGWeights(XGBoost_20_6, 'XGBoost_20_6' + strong_data_sfx, 6)\n",
    "print('--------------------------------')\n",
    "\n",
    "\n",
    "XGBoost_40_4 = buildXG(10, 0.3, 0.5, 0.9, 2, 40, 4)\n",
    "# Either train or load weights\n",
    "if (train_model): XGBoost_40_4 = trainXG(XGBoost_40_4) #train\n",
    "else: XGBoost_40_4.load_model('./XGBoost_40_4' + strong_data_sfx) #load\n",
    "# Save weights\n",
    "XGBoost_40_4.save_model('./XGBoost_40_4' + strong_data_sfx)\n",
    "preds = XGBoost_40_4.predict(test_dataset)\n",
    "if (show_perf): evaluatePerf(test_labels, preds)\n",
    "print('--------------------------------')\n",
    "extractXGWeights(XGBoost_40_4, 'XGBoost_40_4' + strong_data_sfx, 4)\n",
    "print('--------------------------------')\n",
    "\n",
    "\n",
    "XGBoost_64_4 = buildXG(10, 0.3, 0.5, 0.9, 2, 64, 4)\n",
    "# Either train or load weights\n",
    "if (train_model): XGBoost_64_4 = trainXG(XGBoost_64_4) #train\n",
    "else: XGBoost_64_4.load_model('./XGBoost_64_4' + strong_data_sfx) #load\n",
    "# Save weights\n",
    "XGBoost_64_4.save_model('./XGBoost_64_4' + strong_data_sfx)\n",
    "preds = XGBoost_64_4.predict(test_dataset)\n",
    "if (show_perf): evaluatePerf(test_labels, preds)\n",
    "print('--------------------------------')\n",
    "extractXGWeights(XGBoost_64_4, 'XGBoost_64_4' + strong_data_sfx, 4)\n",
    "print('--------------------------------')\n",
    "\n",
    "XGBoost_96_4 = buildXG(10, 0.3, 0.5, 0.9, 2, 96, 4)\n",
    "# Either train or load weights\n",
    "if (train_model): XGBoost_96_4 = trainXG(XGBoost_96_4) #train\n",
    "else: XGBoost_96_4.load_model('./XGBoost_96_4' + strong_data_sfx) #load\n",
    "# Save weights\n",
    "XGBoost_96_4.save_model('./XGBoost_96_4' + strong_data_sfx)\n",
    "preds = XGBoost_96_4.predict(test_dataset)\n",
    "if (show_perf): evaluatePerf(test_labels, preds)\n",
    "print('--------------------------------')\n",
    "extractXGWeights(XGBoost_96_4, 'XGBoost_96_4' + strong_data_sfx, 4)\n",
    "print('--------------------------------')\n",
    "\n",
    "\n",
    "XGBoost_128_4 = buildXG(10, 0.3, 0.5, 0.9, 2, 128, 4)\n",
    "# Either train or load weights\n",
    "if (train_model): XGBoost_128_4 = trainXG(XGBoost_128_4) #train\n",
    "else: XGBoost_128_4.load_model('./XGBoost_128_4' + strong_data_sfx) #load\n",
    "# Save weights\n",
    "XGBoost_128_4.save_model('./XGBoost_128_4' + strong_data_sfx)\n",
    "preds = XGBoost_128_4.predict(test_dataset)\n",
    "if (show_perf): evaluatePerf(test_labels, preds)\n",
    "print('--------------------------------')\n",
    "extractXGWeights(XGBoost_128_4, 'XGBoost_128_4' + strong_data_sfx, 4)\n",
    "print('--------------------------------')\n",
    "\n",
    "\n",
    "XGBoost_128_3 = buildXG(10, 0.3, 0.5, 0.9, 2, 128, 3)\n",
    "# Either train or load weights\n",
    "if (train_model): XGBoost_128_3 = trainXG(XGBoost_128_3) #train\n",
    "else: XGBoost_128_3.load_model('./XGBoost_128_3' + strong_data_sfx) #load\n",
    "# Save weights\n",
    "XGBoost_128_3.save_model('./XGBoost_128_3' + strong_data_sfx)\n",
    "preds = XGBoost_128_3.predict(test_dataset)\n",
    "if (show_perf): evaluatePerf(test_labels, preds)\n",
    "print('--------------------------------')\n",
    "extractXGWeights(XGBoost_128_3, 'XGBoost_128_3' + strong_data_sfx, 3)\n",
    "print('--------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'buildXG' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8f1458a8a18f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mXGBoost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuildXG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Depth:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Either train or load weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'buildXG' is not defined"
     ]
    }
   ],
   "source": [
    "train_model = False\n",
    "for depth in range(6, 14):\n",
    "    XGBoost = buildXG(10, 0.3, 0.5, 0.9, 2, 128, depth)\n",
    "    print(\"Depth:\", depth)\n",
    "    # Either train or load weights\n",
    "    if (train_model): XGBoost = trainXG(XGBoost) #train\n",
    "    else: XGBoost.load_model(f'./XGBoost_128_{depth}' + strong_data_sfx) #load\n",
    "    # Save weights\n",
    "    print(depth)\n",
    "    extractXGWeights_(XGBoost)\n",
    "    XGBoost.save_model(f'./XGBoost_128_{depth}' + strong_data_sfx)\n",
    "    preds = XGBoost.predict(test_dataset)\n",
    "    if (show_perf): evaluatePerf(test_labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, columns = buildDataset()\n",
    "dataset = filterBad(dataset, only_use_strong)\n",
    "dataset = scaleVolume(dataset, 4096)\n",
    "# dataset, columns = dropColumns(dataset, ['fileId'])\n",
    "train_dataset, test_dataset, train_labels, test_labels = splitDataset(dataset, 0.1)\n",
    "\n",
    "worstOffenders(test_labels, preds, test_dataset, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = xgb.DMatrix(pd.DataFrame({\"rising_idx\":[157],\n",
    "#     \"falling_idx\":[341],\n",
    "#     \"volume\":[12039],\n",
    "#     \"rising_weight\":[35.2498],\n",
    "#     \"falling_weight\":[-28.1037]}))\n",
    "df2 = pd.DataFrame({\n",
    "    \"row\":[0],\n",
    "    \"rising_idx\":[157],\n",
    "    \"falling_idx\":[341],\n",
    "    \"volume\":[12039],\n",
    "    \"rising_weight\":[35.2498],\n",
    "    \"falling_weight\":[-28.1037], \n",
    "    \"first_val\":[12],\n",
    "    \"last_val\":[0]})\n",
    "df2 = pd.DataFrame({\n",
    "    \"row\":[0],\n",
    "    \"rising_idx\":[0],\n",
    "    \"falling_idx\":[0],\n",
    "    \"volume\":[0],\n",
    "    \"rising_weight\":[0.0],\n",
    "    \"falling_weight\":[-0.0], \n",
    "    \"first_val\":[0],\n",
    "    \"last_val\":[0]})\n",
    "print(XGBoost_10_5.predict(df2))\n",
    "print('True label = %f' % 509.093)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = XGBoost_10_5.predict(test_dataset)\n",
    "xgb.plot_importance(XGBoost_10_5)\n",
    "plt.rcParams['figure.figsize'] = [50,10]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']= 500\n",
    "\n",
    "xgb.plot_tree(XGBoost_10_5,num_trees=1)\n",
    "plt.rcParams['figure.figsize'] = [50, 10]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.10.0-py3-none-any.whl (215 kB)\n",
      "\u001b[K     |████████████████████████████████| 215 kB 30.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.0.1 in /home/stanfurd/lattice_experiments/lattice_env/lib/python3.6/site-packages (from seaborn) (1.4.1)\n",
      "Requirement already satisfied: matplotlib>=2.1.2 in /home/stanfurd/lattice_experiments/lattice_env/lib/python3.6/site-packages (from seaborn) (3.1.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/stanfurd/lattice_experiments/lattice_env/lib/python3.6/site-packages (from seaborn) (1.18.1)\n",
      "Requirement already satisfied: pandas>=0.22.0 in /home/stanfurd/lattice_experiments/lattice_env/lib/python3.6/site-packages (from seaborn) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/stanfurd/lattice_experiments/lattice_env/lib/python3.6/site-packages (from matplotlib>=2.1.2->seaborn) (2.4.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/stanfurd/lattice_experiments/lattice_env/lib/python3.6/site-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/stanfurd/lattice_experiments/lattice_env/lib/python3.6/site-packages (from matplotlib>=2.1.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/stanfurd/lattice_experiments/lattice_env/lib/python3.6/site-packages (from matplotlib>=2.1.2->seaborn) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/stanfurd/lattice_experiments/lattice_env/lib/python3.6/site-packages (from pandas>=0.22.0->seaborn) (2019.3)\n",
      "Requirement already satisfied: six in /home/stanfurd/lattice_experiments/lattice_env/lib/python3.6/site-packages (from cycler>=0.10->matplotlib>=2.1.2->seaborn) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /home/stanfurd/lattice_experiments/lattice_env/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.2->seaborn) (45.1.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataset.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
